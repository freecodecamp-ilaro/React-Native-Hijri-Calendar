{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_2_4 students FF_Gan_cifar10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP1lSOlwXeVu8TyLPOIB2xD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/musab-r/React-Native-Hijri-Calendar/blob/master/CIFAR10/1_2_4_students_FF_Gan_cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_QUM9A-is9R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imgZBevn_klO"
      },
      "source": [
        "# %tensorflow_version 1.x\n",
        "# !pip install --upgrade opencv-python==3.4.2.17\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "import tensorflow.keras.backend as K\n",
        "# import os\n",
        "from tensorflow.keras.datasets import fashion_mnist,mnist,cifar10\n",
        "# import keras.backend as K\n",
        "from tensorflow.keras.layers import Conv2D,Activation,BatchNormalization,UpSampling2D,Embedding,ZeroPadding2D, Input, Flatten, Dense, Reshape, LeakyReLU, Dropout,MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "from tensorflow.keras.utils import Progbar\n",
        "from keras.initializers import RandomNormal\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from keras.utils import np_utils\n",
        "from tensorflow.keras import utils as np_utils\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0-DYwB8kiFk"
      },
      "source": [
        "nb_classes = 10\n",
        "batch_size = 128\n",
        "maxepoches = 250\n",
        "learning_rate = 0.1\n",
        "lr_decay = 1e-6\n",
        "lr_drop = 20\n",
        "def lr_scheduler(epoch):\n",
        "    return learning_rate * (0.5 ** (epoch // lr_drop))\n",
        "reduce_lr = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e04yi6rW_qJg"
      },
      "source": [
        "#Loading and splitting the dataset into train, validation and test\n",
        "\n",
        "\n",
        "(X_Train, y_Train), (X_test, y_test) = cifar10.load_data()\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_Train, y_Train, test_size=0.20)\n",
        "# convert y_train and y_test to categorical binary values \n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_val = np_utils.to_categorical(y_val, nb_classes)\n",
        "y_test = np_utils.to_categorical(y_test, nb_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj_XM_dfmqnV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "693c21c8-a57b-48dd-b592-74f18de6244e"
      },
      "source": [
        "X_Train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "443_UL2p_qyQ"
      },
      "source": [
        "# Reshape them to batch_size, width,height,#channels\n",
        "X_train = X_train.reshape(40000, 32, 32, 3)\n",
        "X_val = X_val.reshape(10000, 32, 32, 3)\n",
        "X_test = X_test.reshape(10000, 32, 32, 3)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_val = X_val.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# Normalize the values\n",
        "X_train /= 255\n",
        "X_val /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aQn2hUFNVDY"
      },
      "source": [
        "init=RandomNormal(mean=0,stddev=0.02)\n",
        "input_shape = (32, 32, 3) # Input shape of each image\n",
        "weight_decay = 0.0005\n",
        "def build_model():\n",
        "    # Build the network of vgg for 10 classes with massive dropout and weight decay as described in the paper.\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), padding='same',\n",
        "                     input_shape=input_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "\n",
        "    model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,kernel_regularizer=regularizers.l2(weight_decay), name='dense_1'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, name='dense_2'))\n",
        "    model.add(Activation('softmax'))\n",
        "    return model\n",
        "teacher = build_model()\n",
        "\n",
        "sgd = SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
        "\n",
        "teacher.compile(loss='categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp4il80HMRFn"
      },
      "source": [
        "teacher.fit(X_train,Y_train,batch_size=128,epochs=150,verbose=1,callbacks=[reduce_lr],validation_data=(X_val,Y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ni98bXDhOi4w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "768f946d-e896-485f-c24f-33bcd905f934"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "path = F\"/content/gdrive/MyDrive/Cifar10/teacher_cifar10.h5\" \n",
        "teacher.load_weights(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBZO-MXLmml_",
        "outputId": "29724a06-3910-4b69-8691-1d29fa7e6a6c"
      },
      "source": [
        "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
        "loss, acc =teacher.evaluate(X_test, y_test, verbose=1)\n",
        "loss, acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 36s 11ms/step - loss: 0.8109 - accuracy: 0.9023\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8068325519561768, 0.901199996471405)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPVxVj6L_sCz"
      },
      "source": [
        "#Collect the dense vector from the previous layer output and store it in a different model\n",
        "teacher_WO_Softmax = Model(teacher.input, teacher.get_layer('dense_1').output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhcEQ0Z-_scF"
      },
      "source": [
        "#Extracting dense representation from the teacher network\n",
        "train_dense = teacher_WO_Softmax.predict(X_train)\n",
        "val_dense = teacher_WO_Softmax.predict(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XG0WGCpM_suF"
      },
      "source": [
        "#Splitting the training dense vector among N students(in this case 2)\n",
        "s1Train=train_dense[:,:64]\n",
        "s2Train=train_dense[:,64:128]\n",
        "s3Train=train_dense[:,128:192]\n",
        "s4Train=train_dense[:,192:]\n",
        "\n",
        "s1Val=val_dense[:,:64]\n",
        "s2Val=val_dense[:,64:128]\n",
        "s3Val=val_dense[:,128:192]\n",
        "s4Val=val_dense[:,192:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "899mGHR-BGkh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKx8VcoJxwH0"
      },
      "source": [
        "def define_model(name):\n",
        "  model2 = Sequential()\n",
        "  # model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3),name=name))\n",
        "  weight_decay = 1e-4\n",
        "  model2 = Sequential()\n",
        "  model2.add(Conv2D(32, (3,3), padding='same', input_shape=(32,32,3), name=name))\n",
        "  model2.add(Activation('elu'))\n",
        "  model2.add(BatchNormalization())\n",
        "  model2.add(Conv2D(32, (3,3), padding='same'))\n",
        "  model2.add(Activation('elu'))\n",
        "  model2.add(BatchNormalization())\n",
        "  model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model2.add(Dropout(0.2))\n",
        "\n",
        "  model2.add(Conv2D(64, (3,3), padding='same'))\n",
        "  model2.add(Activation('elu'))\n",
        "  model2.add(BatchNormalization())\n",
        "  model2.add(Conv2D(64, (3,3), padding='same'))\n",
        "  model2.add(Activation('elu'))\n",
        "  model2.add(BatchNormalization())\n",
        "  model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model2.add(Dropout(0.3))\n",
        "\n",
        "  model2.add(Flatten())\n",
        "  model2.add(Dense(16, activation='relu'))\n",
        "  model2.add(Dense(64, activation='relu',name='req'+name))\n",
        "\n",
        "  model2.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
        "  return model2\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Bf51HQeYB19"
      },
      "source": [
        "# import np.random import random\n",
        "BATCH_SIZE=32\n",
        "def smooth_real_labels(y):\n",
        "    return y - 0.3+(np.random.random(y.shape)*0.5)\n",
        "def smooth_fake_labels(y):\n",
        "    return y + (0.3 * np.random.random(y.shape))\n",
        "def build_gan(gen,disc): \n",
        "    disc.trainable = False\n",
        "    input= Input(shape=input_shape)\n",
        "    output = gen(input)\n",
        "    output2= disc(output)\n",
        "    gan=Model(input,output2)\n",
        "\n",
        "    gan.compile('adam',loss=['binary_crossentropy','mse'],metrics=['accuracy'])\n",
        "\n",
        "    return gan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DN9rlsCXBHl"
      },
      "source": [
        "def build_sdiscriminator():\n",
        "    \n",
        "    input2 = Input(shape=(256,),name='input')\n",
        "    inp=Dense(128)(input2)\n",
        "\n",
        "    leaky_relu = LeakyReLU(alpha=0.2)(inp)\n",
        "    \n",
        "    conv3 = Dense(128,activation='relu')(leaky_relu)\n",
        "    b_n = BatchNormalization()(conv3)\n",
        "    # leaky_relu = LeakyReLU(alpha=0.2)(b_n)\n",
        "    conv3 = Dense(128,activation='relu')(leaky_relu)\n",
        "    b_n = BatchNormalization()(conv3)\n",
        "    # leaky_relu = LeakyReLU(alpha=0.2)(b_n)\n",
        "    conv3 = Dense(128,activation='relu')(b_n)\n",
        "    b_n = BatchNormalization()(conv3)\n",
        "    # leaky_relu = LeakyReLU(alpha=0.2)(b_n)\n",
        "    conv4 = Dense(256,activation='relu')(b_n)\n",
        "    b_n = BatchNormalization()(conv4)\n",
        "    # leaky_relu = LeakyReLU(alpha=0.2)(b_n)\n",
        "    conv4 = Dense(256,activation='relu')(b_n)\n",
        "    b_n = BatchNormalization()(conv4)\n",
        "    leaky_relu = LeakyReLU(alpha=0.2)(b_n)\n",
        "    conv4 = Dense(512)(leaky_relu)\n",
        "    b_n = BatchNormalization()(conv4)\n",
        "    leaky_relu = LeakyReLU(alpha=0.2)(b_n)\n",
        "    conv4 = Dense(512,activation='relu')(b_n)\n",
        "    b_n = BatchNormalization()(conv4)\n",
        "    leaky_relu = LeakyReLU(alpha=0.2)(b_n)\n",
        "    conv4 = Dense(1024)(leaky_relu)\n",
        "    b_n = BatchNormalization()(conv4)\n",
        "    leaky_relu = LeakyReLU(alpha=0.2)(b_n)\n",
        "\n",
        "    dense = Dense(1,activation='sigmoid')(b_n)\n",
        "\n",
        "    output2=Dense(256)(b_n)\n",
        "\n",
        "    \n",
        "    disc = Model(input2,[dense,output2])          \n",
        "    disc.compile(optd,loss=['binary_crossentropy','mse'],metrics=['accuracy'])\n",
        "\n",
        "\n",
        "    return disc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP0r1sO5ACHS"
      },
      "source": [
        "def training(generator,discriminator,gan,features,epo=20):\n",
        "    # Setup Models here\n",
        "    BATCH_SIZE = 128\n",
        "    discriminator.trainable = True\n",
        "    total_size = X_train.shape[0]\n",
        "    indices = np.arange(0,total_size ,BATCH_SIZE)\n",
        "    all_disc_loss = []\n",
        "    all_gen_loss = []\n",
        "    all_class_loss=[]\n",
        "    if total_size % BATCH_SIZE:\n",
        "        indices = indices[:-1]\n",
        "    for e in range(epo):\n",
        "        \n",
        "        progress_bar = Progbar(target=len(indices))\n",
        "        np.random.shuffle(indices)\n",
        "        epoch_gen_loss = []\n",
        "        epoch_disc_loss = []\n",
        "        epoch_class_loss= []\n",
        "        for i,index in enumerate(indices):\n",
        "        \n",
        "            # Write your code here\n",
        "            inputs=X_train[index:index+BATCH_SIZE]\n",
        "            real_image = features[index:index+BATCH_SIZE]\n",
        "            y_train = features[index:index+BATCH_SIZE]\n",
        "\n",
        "            y_real = np.ones((BATCH_SIZE,1))\n",
        "            y_fake = np.zeros((BATCH_SIZE,1))\n",
        "\n",
        "            #Generator Training\n",
        "            fake_images = generator.predict_on_batch(inputs)\n",
        "\n",
        "            #Disrciminator Training\n",
        "            disc_real_loss1,_,disc_real_loss2,_,_= discriminator.train_on_batch(real_image,[y_real,y_train])\n",
        "            disc_fake_loss1,_,disc_fake_loss2,_,_= discriminator.train_on_batch(fake_images,[y_fake,y_train])\n",
        "\n",
        "            #Gans Training\n",
        "            discriminator.trainable = False\n",
        "            gan_loss,_,gan_loss2,_,_ = gan.train_on_batch(inputs, [y_real,y_train])\n",
        "            gan_loss,_,gan_loss2,_,_ = gan.train_on_batch(inputs, [y_real,y_train])\n",
        "            gan_loss,_,gan_loss2,_,_ = gan.train_on_batch(inputs, [y_real,y_train])\n",
        "            gan_loss,_,gan_loss2,_,_ = gan.train_on_batch(inputs, [y_real,y_train])\n",
        "\n",
        "            discriminator.trainable = True\n",
        "\n",
        "            disc_loss = (disc_fake_loss1 + disc_real_loss1)/2\n",
        "            epoch_disc_loss.append(disc_loss)\n",
        "            progress_bar.update(i+1)\n",
        "\n",
        "            epoch_gen_loss.append((gan_loss))\n",
        "\n",
        "        avg_epoch_disc_loss = np.array(epoch_disc_loss).mean()\n",
        "        avg_epoch_gen_loss = np.array(epoch_gen_loss).mean()\n",
        "        all_disc_loss.append(avg_epoch_disc_loss)\n",
        "        all_gen_loss.append(avg_epoch_gen_loss)\n",
        "        print(\"Epoch: %d | Discriminator Loss: %f | Generator Loss: %f | \" % (e+1,avg_epoch_disc_loss,avg_epoch_gen_loss))\n",
        "\n",
        "    return generator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLVy1YMxrpVo"
      },
      "source": [
        "## 1 Student"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMuyg_3pACVM",
        "outputId": "4407b98d-4bd3-470a-f44a-d5e0d4b6852c"
      },
      "source": [
        "optd = Adam(lr=0.0002)\n",
        "opt = Adam(lr=0.0001)\n",
        "\n",
        "discriminator1 = build_sdiscriminator()\n",
        "s1=define_model(\"s1\")\n",
        "gan1 = build_gan(s1,discriminator1)\n",
        "s1 = training(s1,discriminator1,gan1,s1Train,epo=40)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "312/312 [==============================] - 41s 120ms/step\n",
            "Epoch: 1 | Discriminator Loss: 1.542770 | Generator Loss: 1.765076 | \n",
            "312/312 [==============================] - 38s 121ms/step\n",
            "Epoch: 2 | Discriminator Loss: 1.075580 | Generator Loss: 1.358143 | \n",
            "312/312 [==============================] - 38s 120ms/step\n",
            "Epoch: 3 | Discriminator Loss: 1.013295 | Generator Loss: 1.262494 | \n",
            "312/312 [==============================] - 38s 120ms/step\n",
            "Epoch: 4 | Discriminator Loss: 0.976509 | Generator Loss: 1.203966 | \n",
            "312/312 [==============================] - 38s 121ms/step\n",
            "Epoch: 5 | Discriminator Loss: 0.943853 | Generator Loss: 1.159379 | \n",
            "312/312 [==============================] - 38s 121ms/step\n",
            "Epoch: 6 | Discriminator Loss: 0.918019 | Generator Loss: 1.124000 | \n",
            "312/312 [==============================] - 38s 120ms/step\n",
            "Epoch: 7 | Discriminator Loss: 0.899429 | Generator Loss: 1.095573 | \n",
            "312/312 [==============================] - 38s 121ms/step\n",
            "Epoch: 8 | Discriminator Loss: 0.884652 | Generator Loss: 1.078823 | \n",
            "312/312 [==============================] - 38s 121ms/step\n",
            "Epoch: 9 | Discriminator Loss: 0.868407 | Generator Loss: 1.057162 | \n",
            "312/312 [==============================] - 38s 122ms/step\n",
            "Epoch: 10 | Discriminator Loss: 0.856908 | Generator Loss: 1.043314 | \n",
            "312/312 [==============================] - 38s 121ms/step\n",
            "Epoch: 11 | Discriminator Loss: 0.849810 | Generator Loss: 1.031319 | \n",
            "312/312 [==============================] - 38s 123ms/step\n",
            "Epoch: 12 | Discriminator Loss: 0.839243 | Generator Loss: 1.016754 | \n",
            "312/312 [==============================] - 38s 123ms/step\n",
            "Epoch: 13 | Discriminator Loss: 0.835669 | Generator Loss: 1.012251 | \n",
            "312/312 [==============================] - 38s 122ms/step\n",
            "Epoch: 14 | Discriminator Loss: 0.829252 | Generator Loss: 1.003298 | \n",
            "312/312 [==============================] - 38s 122ms/step\n",
            "Epoch: 15 | Discriminator Loss: 0.825374 | Generator Loss: 0.998585 | \n",
            "312/312 [==============================] - 38s 122ms/step\n",
            "Epoch: 16 | Discriminator Loss: 0.815596 | Generator Loss: 0.988427 | \n",
            "312/312 [==============================] - 38s 121ms/step\n",
            "Epoch: 17 | Discriminator Loss: 0.813963 | Generator Loss: 0.985435 | \n",
            "312/312 [==============================] - 38s 123ms/step\n",
            "Epoch: 18 | Discriminator Loss: 0.811229 | Generator Loss: 0.981788 | \n",
            "312/312 [==============================] - 38s 122ms/step\n",
            "Epoch: 19 | Discriminator Loss: 0.807402 | Generator Loss: 0.972608 | \n",
            "312/312 [==============================] - 38s 121ms/step\n",
            "Epoch: 20 | Discriminator Loss: 0.802558 | Generator Loss: 0.969797 | \n",
            "312/312 [==============================] - 38s 121ms/step\n",
            "Epoch: 21 | Discriminator Loss: 0.799906 | Generator Loss: 0.965737 | \n",
            "312/312 [==============================] - 38s 121ms/step\n",
            "Epoch: 22 | Discriminator Loss: 0.796813 | Generator Loss: 0.962240 | \n",
            "312/312 [==============================] - 38s 121ms/step\n",
            "Epoch: 23 | Discriminator Loss: 0.794629 | Generator Loss: 0.955108 | \n",
            "312/312 [==============================] - 38s 121ms/step\n",
            "Epoch: 24 | Discriminator Loss: 0.790176 | Generator Loss: 0.955783 | \n",
            "312/312 [==============================] - 38s 122ms/step\n",
            "Epoch: 25 | Discriminator Loss: 0.790338 | Generator Loss: 0.951497 | \n",
            "312/312 [==============================] - 38s 122ms/step\n",
            "Epoch: 26 | Discriminator Loss: 0.785725 | Generator Loss: 0.947680 | \n",
            "312/312 [==============================] - 38s 122ms/step\n",
            "Epoch: 27 | Discriminator Loss: 0.786138 | Generator Loss: 0.945610 | \n",
            "312/312 [==============================] - 38s 122ms/step\n",
            "Epoch: 28 | Discriminator Loss: 0.784604 | Generator Loss: 0.941497 | \n",
            "312/312 [==============================] - 38s 122ms/step\n",
            "Epoch: 29 | Discriminator Loss: 0.783514 | Generator Loss: 0.942954 | \n",
            "312/312 [==============================] - 38s 122ms/step\n",
            "Epoch: 30 | Discriminator Loss: 0.781123 | Generator Loss: 0.943051 | \n",
            "312/312 [==============================] - 38s 122ms/step\n",
            "Epoch: 31 | Discriminator Loss: 0.778627 | Generator Loss: 0.937047 | \n",
            "312/312 [==============================] - 38s 120ms/step\n",
            "Epoch: 32 | Discriminator Loss: 0.778398 | Generator Loss: 0.934541 | \n",
            "312/312 [==============================] - 38s 121ms/step\n",
            "Epoch: 33 | Discriminator Loss: 0.778826 | Generator Loss: 0.935354 | \n",
            "312/312 [==============================] - 38s 121ms/step\n",
            "Epoch: 34 | Discriminator Loss: 0.778000 | Generator Loss: 0.931748 | \n",
            "312/312 [==============================] - 38s 123ms/step\n",
            "Epoch: 35 | Discriminator Loss: 0.777669 | Generator Loss: 0.933332 | \n",
            "312/312 [==============================] - 38s 121ms/step\n",
            "Epoch: 36 | Discriminator Loss: 0.776150 | Generator Loss: 0.928918 | \n",
            "312/312 [==============================] - 38s 122ms/step\n",
            "Epoch: 37 | Discriminator Loss: 0.772980 | Generator Loss: 0.925238 | \n",
            "312/312 [==============================] - 38s 122ms/step\n",
            "Epoch: 38 | Discriminator Loss: 0.772441 | Generator Loss: 0.928663 | \n",
            "312/312 [==============================] - 38s 121ms/step\n",
            "Epoch: 39 | Discriminator Loss: 0.770368 | Generator Loss: 0.924879 | \n",
            "312/312 [==============================] - 38s 122ms/step\n",
            "Epoch: 40 | Discriminator Loss: 0.770013 | Generator Loss: 0.923373 | \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SF0whGaBMjz"
      },
      "source": [
        "o1=s1.get_layer(\"reqs1\").output\n",
        "\n",
        "output=Activation('relu')(o1)\n",
        "output2=Dropout(0.5)(output)\n",
        "output3=Dense(10,activation=\"softmax\", name=\"d1\")(output2)\n",
        "mm1=Model(s1.get_layer('s1').input, output3)\n",
        "my_weights=teacher.get_layer('dense_2').get_weights()\n",
        "\n",
        "# multi_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7gP-upUPA7C",
        "outputId": "3b266062-f7fc-46b0-994e-0624a1f90e56"
      },
      "source": [
        "mm1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "s1_input (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "s1 (Conv2D)                  (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_29 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_56 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_52 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_30 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_57 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_31 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_39 (Dropout)         (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_53 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_31 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_58 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_54 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_32 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_59 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_32 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_40 (Dropout)         (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 16)                65552     \n",
            "_________________________________________________________________\n",
            "reqs1 (Dense)                (None, 256)               4352      \n",
            "_________________________________________________________________\n",
            "activation_33 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_41 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "d1 (Dense)                   (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 138,810\n",
            "Trainable params: 138,426\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw_XLiVWBmij"
      },
      "source": [
        "#assigning the extracted weights as a starting point to the combined student network\n",
        "mm1.get_layer('d1').set_weights(my_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa1YEvef3nhi"
      },
      "source": [
        "i=0\n",
        "for l in mm1.layers[:len(mm1.layers)-2]:\n",
        "    l.trainable=False\n",
        "#     print(l)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2Ys_A3GBvqi"
      },
      "source": [
        "mm1.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da5xVGuhOKww",
        "outputId": "966955f9-bf0b-439b-c541-d1fcc209165b"
      },
      "source": [
        "# With finetune\n",
        "batch_size = 256\n",
        "mm_history=mm1.fit(X_train, Y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=20,\n",
        "          verbose=1,\n",
        "          validation_data=(X_val, Y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "157/157 [==============================] - 3s 15ms/step - loss: 0.4683 - accuracy: 0.8850 - val_loss: 0.6904 - val_accuracy: 0.8104\n",
            "Epoch 2/20\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.4727 - accuracy: 0.8849 - val_loss: 0.6912 - val_accuracy: 0.8098\n",
            "Epoch 3/20\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.4806 - accuracy: 0.8804 - val_loss: 0.6943 - val_accuracy: 0.8073\n",
            "Epoch 4/20\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.4821 - accuracy: 0.8809 - val_loss: 0.6937 - val_accuracy: 0.8084\n",
            "Epoch 5/20\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.4890 - accuracy: 0.8778 - val_loss: 0.6972 - val_accuracy: 0.8090\n",
            "Epoch 6/20\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.4842 - accuracy: 0.8788 - val_loss: 0.6973 - val_accuracy: 0.8111\n",
            "Epoch 7/20\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.4686 - accuracy: 0.8804 - val_loss: 0.6971 - val_accuracy: 0.8098\n",
            "Epoch 8/20\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.4779 - accuracy: 0.8841 - val_loss: 0.7018 - val_accuracy: 0.8096\n",
            "Epoch 9/20\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.4746 - accuracy: 0.8846 - val_loss: 0.6992 - val_accuracy: 0.8108\n",
            "Epoch 10/20\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.4731 - accuracy: 0.8803 - val_loss: 0.7049 - val_accuracy: 0.8081\n",
            "Epoch 11/20\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.4737 - accuracy: 0.8862 - val_loss: 0.7023 - val_accuracy: 0.8097\n",
            "Epoch 12/20\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.4774 - accuracy: 0.8801 - val_loss: 0.7059 - val_accuracy: 0.8092\n",
            "Epoch 13/20\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.4735 - accuracy: 0.8860 - val_loss: 0.7007 - val_accuracy: 0.8102\n",
            "Epoch 14/20\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.4795 - accuracy: 0.8821 - val_loss: 0.7036 - val_accuracy: 0.8082\n",
            "Epoch 15/20\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.4870 - accuracy: 0.8823 - val_loss: 0.7057 - val_accuracy: 0.8096\n",
            "Epoch 16/20\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.4891 - accuracy: 0.8804 - val_loss: 0.7043 - val_accuracy: 0.8094\n",
            "Epoch 17/20\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.4668 - accuracy: 0.8876 - val_loss: 0.7080 - val_accuracy: 0.8079\n",
            "Epoch 18/20\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.4775 - accuracy: 0.8825 - val_loss: 0.7064 - val_accuracy: 0.8087\n",
            "Epoch 19/20\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.4713 - accuracy: 0.8820 - val_loss: 0.7052 - val_accuracy: 0.8089\n",
            "Epoch 20/20\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.4861 - accuracy: 0.8834 - val_loss: 0.7069 - val_accuracy: 0.8073\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVMLsA0LBnSD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35ac6134-f955-4f63-a7d5-0863df8b751a"
      },
      "source": [
        "batch_size = 256\n",
        "mm_history=mm1.fit(X_train, Y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=10,\n",
        "          verbose=1,\n",
        "          validation_data=(X_val, Y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "157/157 [==============================] - 4s 23ms/step - loss: 0.3923 - accuracy: 0.8772 - val_loss: 0.5692 - val_accuracy: 0.8131\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 3s 21ms/step - loss: 0.3871 - accuracy: 0.8774 - val_loss: 0.5692 - val_accuracy: 0.8124\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 3s 21ms/step - loss: 0.3712 - accuracy: 0.8831 - val_loss: 0.5640 - val_accuracy: 0.8168\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 3s 21ms/step - loss: 0.3817 - accuracy: 0.8779 - val_loss: 0.5621 - val_accuracy: 0.8160\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 3s 21ms/step - loss: 0.3645 - accuracy: 0.8834 - val_loss: 0.5649 - val_accuracy: 0.8161\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 3s 21ms/step - loss: 0.3558 - accuracy: 0.8868 - val_loss: 0.5637 - val_accuracy: 0.8194\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 3s 21ms/step - loss: 0.3688 - accuracy: 0.8823 - val_loss: 0.5706 - val_accuracy: 0.8139\n",
            "Epoch 8/10\n",
            "157/157 [==============================] - 3s 21ms/step - loss: 0.3596 - accuracy: 0.8838 - val_loss: 0.5676 - val_accuracy: 0.8147\n",
            "Epoch 9/10\n",
            "157/157 [==============================] - 3s 21ms/step - loss: 0.3608 - accuracy: 0.8862 - val_loss: 0.5679 - val_accuracy: 0.8155\n",
            "Epoch 10/10\n",
            "157/157 [==============================] - 3s 21ms/step - loss: 0.3584 - accuracy: 0.8874 - val_loss: 0.5666 - val_accuracy: 0.8157\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7SsTY8acE59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bbd61b6-a960-4d12-fd51-070aa7da0d19"
      },
      "source": [
        "l,a = mm1.evaluate(X_test, y_test)\n",
        "l, a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 6.3232 - accuracy: 0.2305\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6.2697248458862305, 0.2273000031709671)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_RLuLLV4Rry",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "e5a04232-5568-4ff5-db2a-77d6a7fe2a64"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(mm_history.history['accuracy'])\n",
        "plt.plot(mm_history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(mm_history.history['loss'])\n",
        "plt.plot(mm_history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQlldHWBPJMn"
      },
      "source": [
        "## **2 Students**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7m6SoOWPNDH",
        "outputId": "66c8ec20-ab25-4556-d101-0c96724b84c1"
      },
      "source": [
        "optd = Adam(lr=0.0002)\n",
        "opt = Adam(lr=0.0001)\n",
        "\n",
        "discriminator1 = build_sdiscriminator()\n",
        "discriminator2 = build_sdiscriminator()\n",
        "s1=define_model(\"s1\")\n",
        "s2=define_model(\"s2\")\n",
        "\n",
        "gan1 = build_gan(s1,discriminator1)\n",
        "gan2 = build_gan(s2,discriminator2)\n",
        "s1 = training(s1,discriminator1,gan1,s1Train,epo=90)\n",
        "s2 = training(s2,discriminator2,gan2,s2Train,epo=98)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "312/312 [==============================] - 35s 105ms/step\n",
            "Epoch: 1 | Discriminator Loss: 1.721610 | Generator Loss: 2.085339 | \n",
            "312/312 [==============================] - 32s 104ms/step\n",
            "Epoch: 2 | Discriminator Loss: 1.270868 | Generator Loss: 1.898533 | \n",
            "312/312 [==============================] - 32s 104ms/step\n",
            "Epoch: 3 | Discriminator Loss: 1.150123 | Generator Loss: 1.700116 | \n",
            "312/312 [==============================] - 32s 102ms/step\n",
            "Epoch: 4 | Discriminator Loss: 1.071535 | Generator Loss: 1.570838 | \n",
            "312/312 [==============================] - 31s 100ms/step\n",
            "Epoch: 5 | Discriminator Loss: 1.033438 | Generator Loss: 1.504226 | \n",
            "312/312 [==============================] - 31s 101ms/step\n",
            "Epoch: 6 | Discriminator Loss: 1.007410 | Generator Loss: 1.470378 | \n",
            "312/312 [==============================] - 33s 104ms/step\n",
            "Epoch: 7 | Discriminator Loss: 0.990217 | Generator Loss: 1.444702 | \n",
            "312/312 [==============================] - 33s 105ms/step\n",
            "Epoch: 8 | Discriminator Loss: 0.973856 | Generator Loss: 1.412147 | \n",
            "312/312 [==============================] - 33s 105ms/step\n",
            "Epoch: 9 | Discriminator Loss: 0.960481 | Generator Loss: 1.393940 | \n",
            "312/312 [==============================] - 33s 105ms/step\n",
            "Epoch: 10 | Discriminator Loss: 0.948107 | Generator Loss: 1.369202 | \n",
            "312/312 [==============================] - 33s 105ms/step\n",
            "Epoch: 11 | Discriminator Loss: 0.935014 | Generator Loss: 1.362547 | \n",
            "312/312 [==============================] - 32s 104ms/step\n",
            "Epoch: 12 | Discriminator Loss: 0.925133 | Generator Loss: 1.338956 | \n",
            "312/312 [==============================] - 31s 100ms/step\n",
            "Epoch: 13 | Discriminator Loss: 0.913871 | Generator Loss: 1.336104 | \n",
            "312/312 [==============================] - 31s 98ms/step\n",
            "Epoch: 14 | Discriminator Loss: 0.905422 | Generator Loss: 1.321923 | \n",
            "312/312 [==============================] - 31s 98ms/step\n",
            "Epoch: 15 | Discriminator Loss: 0.897327 | Generator Loss: 1.313741 | \n",
            "312/312 [==============================] - 32s 104ms/step\n",
            "Epoch: 16 | Discriminator Loss: 0.890248 | Generator Loss: 1.305873 | \n",
            "312/312 [==============================] - 33s 105ms/step\n",
            "Epoch: 17 | Discriminator Loss: 0.883429 | Generator Loss: 1.303500 | \n",
            "312/312 [==============================] - 31s 99ms/step\n",
            "Epoch: 18 | Discriminator Loss: 0.875950 | Generator Loss: 1.289418 | \n",
            "312/312 [==============================] - 31s 101ms/step\n",
            "Epoch: 19 | Discriminator Loss: 0.871461 | Generator Loss: 1.278960 | \n",
            "312/312 [==============================] - 32s 101ms/step\n",
            "Epoch: 20 | Discriminator Loss: 0.865849 | Generator Loss: 1.267245 | \n",
            "312/312 [==============================] - 31s 100ms/step\n",
            "Epoch: 21 | Discriminator Loss: 0.861539 | Generator Loss: 1.258151 | \n",
            "312/312 [==============================] - 32s 101ms/step\n",
            "Epoch: 22 | Discriminator Loss: 0.855612 | Generator Loss: 1.254082 | \n",
            "312/312 [==============================] - 31s 100ms/step\n",
            "Epoch: 23 | Discriminator Loss: 0.851108 | Generator Loss: 1.252578 | \n",
            "312/312 [==============================] - 31s 99ms/step\n",
            "Epoch: 24 | Discriminator Loss: 0.847751 | Generator Loss: 1.252790 | \n",
            "312/312 [==============================] - 32s 103ms/step\n",
            "Epoch: 25 | Discriminator Loss: 0.843161 | Generator Loss: 1.243920 | \n",
            "312/312 [==============================] - 33s 105ms/step\n",
            "Epoch: 26 | Discriminator Loss: 0.838712 | Generator Loss: 1.237905 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 27 | Discriminator Loss: 0.835463 | Generator Loss: 1.238056 | \n",
            "312/312 [==============================] - 33s 104ms/step\n",
            "Epoch: 28 | Discriminator Loss: 0.833218 | Generator Loss: 1.233950 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 29 | Discriminator Loss: 0.829329 | Generator Loss: 1.230928 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 30 | Discriminator Loss: 0.826463 | Generator Loss: 1.226345 | \n",
            "312/312 [==============================] - 32s 103ms/step\n",
            "Epoch: 31 | Discriminator Loss: 0.823506 | Generator Loss: 1.231076 | \n",
            "312/312 [==============================] - 31s 99ms/step\n",
            "Epoch: 32 | Discriminator Loss: 0.820491 | Generator Loss: 1.212733 | \n",
            "312/312 [==============================] - 31s 101ms/step\n",
            "Epoch: 33 | Discriminator Loss: 0.818502 | Generator Loss: 1.211771 | \n",
            "312/312 [==============================] - 32s 101ms/step\n",
            "Epoch: 34 | Discriminator Loss: 0.814360 | Generator Loss: 1.196245 | \n",
            "312/312 [==============================] - 33s 105ms/step\n",
            "Epoch: 35 | Discriminator Loss: 0.811041 | Generator Loss: 1.188303 | \n",
            "312/312 [==============================] - 33s 107ms/step\n",
            "Epoch: 36 | Discriminator Loss: 0.809608 | Generator Loss: 1.180314 | \n",
            "312/312 [==============================] - 33s 105ms/step\n",
            "Epoch: 37 | Discriminator Loss: 0.807196 | Generator Loss: 1.170031 | \n",
            "312/312 [==============================] - 33s 105ms/step\n",
            "Epoch: 38 | Discriminator Loss: 0.805454 | Generator Loss: 1.163197 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 39 | Discriminator Loss: 0.802852 | Generator Loss: 1.153709 | \n",
            "312/312 [==============================] - 31s 101ms/step\n",
            "Epoch: 40 | Discriminator Loss: 0.800403 | Generator Loss: 1.150453 | \n",
            "312/312 [==============================] - 32s 102ms/step\n",
            "Epoch: 41 | Discriminator Loss: 0.797861 | Generator Loss: 1.140438 | \n",
            "312/312 [==============================] - 32s 104ms/step\n",
            "Epoch: 42 | Discriminator Loss: 0.795975 | Generator Loss: 1.130550 | \n",
            "312/312 [==============================] - 33s 105ms/step\n",
            "Epoch: 43 | Discriminator Loss: 0.794759 | Generator Loss: 1.121250 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 44 | Discriminator Loss: 0.792107 | Generator Loss: 1.120302 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 45 | Discriminator Loss: 0.791056 | Generator Loss: 1.112978 | \n",
            "312/312 [==============================] - 33s 107ms/step\n",
            "Epoch: 46 | Discriminator Loss: 0.788999 | Generator Loss: 1.109069 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 47 | Discriminator Loss: 0.787251 | Generator Loss: 1.101936 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 48 | Discriminator Loss: 0.786094 | Generator Loss: 1.093921 | \n",
            "312/312 [==============================] - 33s 105ms/step\n",
            "Epoch: 49 | Discriminator Loss: 0.785307 | Generator Loss: 1.097354 | \n",
            "312/312 [==============================] - 32s 101ms/step\n",
            "Epoch: 50 | Discriminator Loss: 0.782985 | Generator Loss: 1.092618 | \n",
            "312/312 [==============================] - 32s 104ms/step\n",
            "Epoch: 51 | Discriminator Loss: 0.781575 | Generator Loss: 1.083220 | \n",
            "312/312 [==============================] - 33s 105ms/step\n",
            "Epoch: 52 | Discriminator Loss: 0.780476 | Generator Loss: 1.083398 | \n",
            "312/312 [==============================] - 32s 103ms/step\n",
            "Epoch: 53 | Discriminator Loss: 0.778695 | Generator Loss: 1.084248 | \n",
            "312/312 [==============================] - 31s 99ms/step\n",
            "Epoch: 54 | Discriminator Loss: 0.778436 | Generator Loss: 1.082533 | \n",
            "312/312 [==============================] - 31s 101ms/step\n",
            "Epoch: 55 | Discriminator Loss: 0.776882 | Generator Loss: 1.083695 | \n",
            "312/312 [==============================] - 31s 100ms/step\n",
            "Epoch: 56 | Discriminator Loss: 0.775090 | Generator Loss: 1.077882 | \n",
            "312/312 [==============================] - 32s 104ms/step\n",
            "Epoch: 57 | Discriminator Loss: 0.774485 | Generator Loss: 1.079470 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 58 | Discriminator Loss: 0.773498 | Generator Loss: 1.075120 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 59 | Discriminator Loss: 0.772142 | Generator Loss: 1.067686 | \n",
            "312/312 [==============================] - 33s 105ms/step\n",
            "Epoch: 60 | Discriminator Loss: 0.771493 | Generator Loss: 1.068668 | \n",
            "312/312 [==============================] - 33s 105ms/step\n",
            "Epoch: 61 | Discriminator Loss: 0.770861 | Generator Loss: 1.066635 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 62 | Discriminator Loss: 0.769968 | Generator Loss: 1.065116 | \n",
            "312/312 [==============================] - 32s 104ms/step\n",
            "Epoch: 63 | Discriminator Loss: 0.768552 | Generator Loss: 1.064675 | \n",
            "312/312 [==============================] - 33s 107ms/step\n",
            "Epoch: 64 | Discriminator Loss: 0.767434 | Generator Loss: 1.058949 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 65 | Discriminator Loss: 0.767031 | Generator Loss: 1.056110 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 66 | Discriminator Loss: 0.765927 | Generator Loss: 1.053810 | \n",
            "312/312 [==============================] - 32s 101ms/step\n",
            "Epoch: 67 | Discriminator Loss: 0.764938 | Generator Loss: 1.053666 | \n",
            "312/312 [==============================] - 32s 101ms/step\n",
            "Epoch: 68 | Discriminator Loss: 0.764017 | Generator Loss: 1.051430 | \n",
            "312/312 [==============================] - 32s 102ms/step\n",
            "Epoch: 69 | Discriminator Loss: 0.763151 | Generator Loss: 1.051500 | \n",
            "312/312 [==============================] - 32s 103ms/step\n",
            "Epoch: 70 | Discriminator Loss: 0.763360 | Generator Loss: 1.056658 | \n",
            "312/312 [==============================] - 32s 102ms/step\n",
            "Epoch: 71 | Discriminator Loss: 0.762294 | Generator Loss: 1.051726 | \n",
            "312/312 [==============================] - 33s 104ms/step\n",
            "Epoch: 72 | Discriminator Loss: 0.761224 | Generator Loss: 1.045284 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 73 | Discriminator Loss: 0.761055 | Generator Loss: 1.047892 | \n",
            "312/312 [==============================] - 33s 107ms/step\n",
            "Epoch: 74 | Discriminator Loss: 0.760026 | Generator Loss: 1.045162 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 75 | Discriminator Loss: 0.760066 | Generator Loss: 1.038961 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 76 | Discriminator Loss: 0.758848 | Generator Loss: 1.035281 | \n",
            "312/312 [==============================] - 33s 105ms/step\n",
            "Epoch: 77 | Discriminator Loss: 0.758472 | Generator Loss: 1.036560 | \n",
            "312/312 [==============================] - 33s 105ms/step\n",
            "Epoch: 78 | Discriminator Loss: 0.757946 | Generator Loss: 1.039379 | \n",
            "312/312 [==============================] - 32s 103ms/step\n",
            "Epoch: 79 | Discriminator Loss: 0.756961 | Generator Loss: 1.031692 | \n",
            "312/312 [==============================] - 31s 100ms/step\n",
            "Epoch: 80 | Discriminator Loss: 0.756827 | Generator Loss: 1.027301 | \n",
            "312/312 [==============================] - 32s 104ms/step\n",
            "Epoch: 81 | Discriminator Loss: 0.756668 | Generator Loss: 1.030964 | \n",
            "312/312 [==============================] - 33s 104ms/step\n",
            "Epoch: 82 | Discriminator Loss: 0.756634 | Generator Loss: 1.028888 | \n",
            "312/312 [==============================] - 33s 107ms/step\n",
            "Epoch: 83 | Discriminator Loss: 0.755416 | Generator Loss: 1.025062 | \n",
            "312/312 [==============================] - 33s 107ms/step\n",
            "Epoch: 84 | Discriminator Loss: 0.755410 | Generator Loss: 1.023304 | \n",
            "312/312 [==============================] - 33s 105ms/step\n",
            "Epoch: 85 | Discriminator Loss: 0.753943 | Generator Loss: 1.023679 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 86 | Discriminator Loss: 0.753820 | Generator Loss: 1.016477 | \n",
            "312/312 [==============================] - 31s 100ms/step\n",
            "Epoch: 87 | Discriminator Loss: 0.753075 | Generator Loss: 1.021878 | \n",
            "312/312 [==============================] - 31s 101ms/step\n",
            "Epoch: 88 | Discriminator Loss: 0.752461 | Generator Loss: 1.020713 | \n",
            "312/312 [==============================] - 32s 103ms/step\n",
            "Epoch: 89 | Discriminator Loss: 0.752408 | Generator Loss: 1.011799 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 90 | Discriminator Loss: 0.752418 | Generator Loss: 1.014723 | \n",
            "312/312 [==============================] - 35s 106ms/step\n",
            "Epoch: 1 | Discriminator Loss: 1.421877 | Generator Loss: 1.923388 | \n",
            "312/312 [==============================] - 33s 105ms/step\n",
            "Epoch: 2 | Discriminator Loss: 1.167452 | Generator Loss: 1.707264 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 3 | Discriminator Loss: 1.067676 | Generator Loss: 1.538373 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 4 | Discriminator Loss: 1.011523 | Generator Loss: 1.429179 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 5 | Discriminator Loss: 0.976373 | Generator Loss: 1.360665 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 6 | Discriminator Loss: 0.952217 | Generator Loss: 1.318082 | \n",
            "312/312 [==============================] - 33s 105ms/step\n",
            "Epoch: 7 | Discriminator Loss: 0.933055 | Generator Loss: 1.283526 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 8 | Discriminator Loss: 0.916675 | Generator Loss: 1.265948 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 9 | Discriminator Loss: 0.903608 | Generator Loss: 1.242761 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 10 | Discriminator Loss: 0.891142 | Generator Loss: 1.222894 | \n",
            "312/312 [==============================] - 33s 107ms/step\n",
            "Epoch: 11 | Discriminator Loss: 0.880140 | Generator Loss: 1.202919 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 12 | Discriminator Loss: 0.871015 | Generator Loss: 1.188837 | \n",
            "312/312 [==============================] - 33s 104ms/step\n",
            "Epoch: 13 | Discriminator Loss: 0.861124 | Generator Loss: 1.169571 | \n",
            "312/312 [==============================] - 33s 107ms/step\n",
            "Epoch: 14 | Discriminator Loss: 0.852907 | Generator Loss: 1.159761 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 15 | Discriminator Loss: 0.845760 | Generator Loss: 1.143036 | \n",
            "312/312 [==============================] - 32s 104ms/step\n",
            "Epoch: 16 | Discriminator Loss: 0.839999 | Generator Loss: 1.131179 | \n",
            "312/312 [==============================] - 32s 102ms/step\n",
            "Epoch: 17 | Discriminator Loss: 0.833738 | Generator Loss: 1.120680 | \n",
            "312/312 [==============================] - 33s 104ms/step\n",
            "Epoch: 18 | Discriminator Loss: 0.828016 | Generator Loss: 1.119149 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 19 | Discriminator Loss: 0.823522 | Generator Loss: 1.111674 | \n",
            "312/312 [==============================] - 32s 102ms/step\n",
            "Epoch: 20 | Discriminator Loss: 0.818712 | Generator Loss: 1.104287 | \n",
            "312/312 [==============================] - 32s 101ms/step\n",
            "Epoch: 21 | Discriminator Loss: 0.815098 | Generator Loss: 1.099488 | \n",
            "312/312 [==============================] - 33s 105ms/step\n",
            "Epoch: 22 | Discriminator Loss: 0.811762 | Generator Loss: 1.100548 | \n",
            "312/312 [==============================] - 33s 105ms/step\n",
            "Epoch: 23 | Discriminator Loss: 0.808123 | Generator Loss: 1.087485 | \n",
            "312/312 [==============================] - 33s 107ms/step\n",
            "Epoch: 24 | Discriminator Loss: 0.804225 | Generator Loss: 1.082114 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 25 | Discriminator Loss: 0.800776 | Generator Loss: 1.078955 | \n",
            "312/312 [==============================] - 32s 104ms/step\n",
            "Epoch: 26 | Discriminator Loss: 0.797910 | Generator Loss: 1.075507 | \n",
            "312/312 [==============================] - 32s 101ms/step\n",
            "Epoch: 27 | Discriminator Loss: 0.795624 | Generator Loss: 1.070779 | \n",
            "312/312 [==============================] - 32s 102ms/step\n",
            "Epoch: 28 | Discriminator Loss: 0.793827 | Generator Loss: 1.068432 | \n",
            "312/312 [==============================] - 33s 107ms/step\n",
            "Epoch: 29 | Discriminator Loss: 0.790281 | Generator Loss: 1.060384 | \n",
            "312/312 [==============================] - 32s 102ms/step\n",
            "Epoch: 30 | Discriminator Loss: 0.788287 | Generator Loss: 1.061445 | \n",
            "312/312 [==============================] - 32s 103ms/step\n",
            "Epoch: 31 | Discriminator Loss: 0.786756 | Generator Loss: 1.054763 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 32 | Discriminator Loss: 0.785556 | Generator Loss: 1.054575 | \n",
            "312/312 [==============================] - 34s 108ms/step\n",
            "Epoch: 33 | Discriminator Loss: 0.783522 | Generator Loss: 1.040902 | \n",
            "312/312 [==============================] - 33s 107ms/step\n",
            "Epoch: 34 | Discriminator Loss: 0.781035 | Generator Loss: 1.042657 | \n",
            "312/312 [==============================] - 33s 107ms/step\n",
            "Epoch: 35 | Discriminator Loss: 0.779099 | Generator Loss: 1.035226 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 36 | Discriminator Loss: 0.777409 | Generator Loss: 1.037365 | \n",
            "312/312 [==============================] - 33s 107ms/step\n",
            "Epoch: 37 | Discriminator Loss: 0.775857 | Generator Loss: 1.032398 | \n",
            "312/312 [==============================] - 33s 107ms/step\n",
            "Epoch: 38 | Discriminator Loss: 0.775321 | Generator Loss: 1.031677 | \n",
            "312/312 [==============================] - 33s 105ms/step\n",
            "Epoch: 39 | Discriminator Loss: 0.772070 | Generator Loss: 1.027510 | \n",
            "312/312 [==============================] - 33s 104ms/step\n",
            "Epoch: 40 | Discriminator Loss: 0.771378 | Generator Loss: 1.022886 | \n",
            "312/312 [==============================] - 34s 108ms/step\n",
            "Epoch: 41 | Discriminator Loss: 0.769549 | Generator Loss: 1.019748 | \n",
            "312/312 [==============================] - 34s 108ms/step\n",
            "Epoch: 42 | Discriminator Loss: 0.769171 | Generator Loss: 1.018932 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 43 | Discriminator Loss: 0.768220 | Generator Loss: 1.014408 | \n",
            "312/312 [==============================] - 33s 107ms/step\n",
            "Epoch: 44 | Discriminator Loss: 0.766211 | Generator Loss: 1.012008 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 45 | Discriminator Loss: 0.766292 | Generator Loss: 1.009718 | \n",
            "312/312 [==============================] - 32s 104ms/step\n",
            "Epoch: 46 | Discriminator Loss: 0.765209 | Generator Loss: 1.008428 | \n",
            "312/312 [==============================] - 33s 105ms/step\n",
            "Epoch: 47 | Discriminator Loss: 0.764332 | Generator Loss: 1.007900 | \n",
            "312/312 [==============================] - 33s 107ms/step\n",
            "Epoch: 48 | Discriminator Loss: 0.763300 | Generator Loss: 1.008241 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 49 | Discriminator Loss: 0.762515 | Generator Loss: 1.002442 | \n",
            "312/312 [==============================] - 33s 107ms/step\n",
            "Epoch: 50 | Discriminator Loss: 0.761451 | Generator Loss: 0.999928 | \n",
            "312/312 [==============================] - 34s 107ms/step\n",
            "Epoch: 51 | Discriminator Loss: 0.760833 | Generator Loss: 0.997283 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 52 | Discriminator Loss: 0.760338 | Generator Loss: 1.001336 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 53 | Discriminator Loss: 0.759093 | Generator Loss: 0.995875 | \n",
            "312/312 [==============================] - 32s 101ms/step\n",
            "Epoch: 54 | Discriminator Loss: 0.758123 | Generator Loss: 0.998741 | \n",
            "312/312 [==============================] - 32s 102ms/step\n",
            "Epoch: 55 | Discriminator Loss: 0.757759 | Generator Loss: 0.994615 | \n",
            "312/312 [==============================] - 32s 101ms/step\n",
            "Epoch: 56 | Discriminator Loss: 0.757163 | Generator Loss: 0.992551 | \n",
            "312/312 [==============================] - 32s 101ms/step\n",
            "Epoch: 57 | Discriminator Loss: 0.756410 | Generator Loss: 0.988926 | \n",
            "312/312 [==============================] - 32s 101ms/step\n",
            "Epoch: 58 | Discriminator Loss: 0.755607 | Generator Loss: 0.984793 | \n",
            "312/312 [==============================] - 32s 102ms/step\n",
            "Epoch: 59 | Discriminator Loss: 0.754647 | Generator Loss: 0.981994 | \n",
            "312/312 [==============================] - 32s 104ms/step\n",
            "Epoch: 60 | Discriminator Loss: 0.754521 | Generator Loss: 0.986292 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 61 | Discriminator Loss: 0.753777 | Generator Loss: 0.984386 | \n",
            "312/312 [==============================] - 33s 107ms/step\n",
            "Epoch: 62 | Discriminator Loss: 0.753224 | Generator Loss: 0.979231 | \n",
            "312/312 [==============================] - 33s 107ms/step\n",
            "Epoch: 63 | Discriminator Loss: 0.752842 | Generator Loss: 0.977298 | \n",
            "312/312 [==============================] - 33s 107ms/step\n",
            "Epoch: 64 | Discriminator Loss: 0.753001 | Generator Loss: 0.975588 | \n",
            "312/312 [==============================] - 33s 107ms/step\n",
            "Epoch: 65 | Discriminator Loss: 0.752568 | Generator Loss: 0.972918 | \n",
            "312/312 [==============================] - 33s 105ms/step\n",
            "Epoch: 66 | Discriminator Loss: 0.752519 | Generator Loss: 0.975127 | \n",
            "312/312 [==============================] - 32s 104ms/step\n",
            "Epoch: 67 | Discriminator Loss: 0.751549 | Generator Loss: 0.975853 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 68 | Discriminator Loss: 0.751522 | Generator Loss: 0.973968 | \n",
            "312/312 [==============================] - 32s 103ms/step\n",
            "Epoch: 69 | Discriminator Loss: 0.751251 | Generator Loss: 0.973866 | \n",
            "312/312 [==============================] - 33s 105ms/step\n",
            "Epoch: 70 | Discriminator Loss: 0.750254 | Generator Loss: 0.969960 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 71 | Discriminator Loss: 0.750217 | Generator Loss: 0.968908 | \n",
            "312/312 [==============================] - 33s 105ms/step\n",
            "Epoch: 72 | Discriminator Loss: 0.749942 | Generator Loss: 0.970249 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 73 | Discriminator Loss: 0.749736 | Generator Loss: 0.968277 | \n",
            "312/312 [==============================] - 33s 107ms/step\n",
            "Epoch: 74 | Discriminator Loss: 0.750071 | Generator Loss: 0.973640 | \n",
            "312/312 [==============================] - 33s 107ms/step\n",
            "Epoch: 75 | Discriminator Loss: 0.748878 | Generator Loss: 0.971381 | \n",
            "312/312 [==============================] - 33s 107ms/step\n",
            "Epoch: 76 | Discriminator Loss: 0.749036 | Generator Loss: 0.972211 | \n",
            "312/312 [==============================] - 33s 107ms/step\n",
            "Epoch: 77 | Discriminator Loss: 0.748583 | Generator Loss: 0.974956 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 78 | Discriminator Loss: 0.748407 | Generator Loss: 0.979725 | \n",
            "312/312 [==============================] - 34s 108ms/step\n",
            "Epoch: 79 | Discriminator Loss: 0.748814 | Generator Loss: 0.979551 | \n",
            "312/312 [==============================] - 33s 107ms/step\n",
            "Epoch: 80 | Discriminator Loss: 0.748447 | Generator Loss: 0.976782 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 81 | Discriminator Loss: 0.748286 | Generator Loss: 0.979566 | \n",
            "312/312 [==============================] - 33s 107ms/step\n",
            "Epoch: 82 | Discriminator Loss: 0.747993 | Generator Loss: 0.978490 | \n",
            "312/312 [==============================] - 32s 102ms/step\n",
            "Epoch: 83 | Discriminator Loss: 0.747292 | Generator Loss: 0.978403 | \n",
            "312/312 [==============================] - 33s 105ms/step\n",
            "Epoch: 84 | Discriminator Loss: 0.747393 | Generator Loss: 0.971401 | \n",
            "312/312 [==============================] - 33s 107ms/step\n",
            "Epoch: 85 | Discriminator Loss: 0.747167 | Generator Loss: 0.973379 | \n",
            "312/312 [==============================] - 34s 107ms/step\n",
            "Epoch: 86 | Discriminator Loss: 0.746317 | Generator Loss: 0.968027 | \n",
            "312/312 [==============================] - 33s 107ms/step\n",
            "Epoch: 87 | Discriminator Loss: 0.746034 | Generator Loss: 0.962846 | \n",
            "312/312 [==============================] - 34s 108ms/step\n",
            "Epoch: 88 | Discriminator Loss: 0.745929 | Generator Loss: 0.963387 | \n",
            "312/312 [==============================] - 33s 107ms/step\n",
            "Epoch: 89 | Discriminator Loss: 0.746205 | Generator Loss: 0.962095 | \n",
            "312/312 [==============================] - 32s 104ms/step\n",
            "Epoch: 90 | Discriminator Loss: 0.746279 | Generator Loss: 0.967670 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 91 | Discriminator Loss: 0.745842 | Generator Loss: 0.966583 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 92 | Discriminator Loss: 0.745952 | Generator Loss: 0.962387 | \n",
            "312/312 [==============================] - 33s 107ms/step\n",
            "Epoch: 93 | Discriminator Loss: 0.745199 | Generator Loss: 0.965217 | \n",
            "312/312 [==============================] - 33s 107ms/step\n",
            "Epoch: 94 | Discriminator Loss: 0.745288 | Generator Loss: 0.962118 | \n",
            "312/312 [==============================] - 34s 107ms/step\n",
            "Epoch: 95 | Discriminator Loss: 0.745199 | Generator Loss: 0.960272 | \n",
            "312/312 [==============================] - 33s 106ms/step\n",
            "Epoch: 96 | Discriminator Loss: 0.745128 | Generator Loss: 0.963027 | \n",
            "312/312 [==============================] - 34s 107ms/step\n",
            "Epoch: 97 | Discriminator Loss: 0.744794 | Generator Loss: 0.957659 | \n",
            "312/312 [==============================] - 34s 108ms/step\n",
            "Epoch: 98 | Discriminator Loss: 0.744087 | Generator Loss: 0.959186 | \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-tJFSFYPXuH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8dmofSbg5ko"
      },
      "source": [
        "o1=s1.get_layer(\"reqs1\").output\n",
        "o2=s2.get_layer(\"reqs2\").output\n",
        "output=tensorflow.keras.layers.concatenate([o1,o2])\n",
        "\n",
        "output=Activation('relu')(output)\n",
        "output2=Dropout(0.5)(output) # For reguralization\n",
        "output3=Dense(10,activation=\"softmax\", name=\"d1\")(output2)\n",
        "\n",
        "mm2=Model([s1.get_layer(\"s1\").input,s2.get_layer(\"s2\").input], output3)\n",
        "my_weights=teacher.get_layer('dense_2').get_weights()\n",
        "mm2.get_layer('d1').set_weights(my_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaSX8xHNg5kx"
      },
      "source": [
        "i=0\n",
        "for l in mm1.layers[:len(mm1.layers)-2]:\n",
        "    l.trainable=False\n",
        "#     print(l)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLz1Oz6dg5ky"
      },
      "source": [
        "mm2.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.0002),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bylsRHBzg5kz",
        "outputId": "c574387e-f8e6-47e1-8aac-13675af7cbf5"
      },
      "source": [
        "# Without finetune\n",
        "batch_size = 256\n",
        "mm2_history=mm2.fit([X_train,X_train], Y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=20,\n",
        "          verbose=1,\n",
        "          validation_data=([X_val,X_val], Y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "157/157 [==============================] - 7s 41ms/step - loss: 6.7863 - accuracy: 0.1538 - val_loss: 1.5426 - val_accuracy: 0.4709\n",
            "Epoch 2/20\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 3.4946 - accuracy: 0.2587 - val_loss: 1.0291 - val_accuracy: 0.6581\n",
            "Epoch 3/20\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 2.4642 - accuracy: 0.3928 - val_loss: 0.7782 - val_accuracy: 0.7586\n",
            "Epoch 4/20\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 1.7563 - accuracy: 0.5479 - val_loss: 0.7103 - val_accuracy: 0.7918\n",
            "Epoch 5/20\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 1.3238 - accuracy: 0.6563 - val_loss: 0.6853 - val_accuracy: 0.8058\n",
            "Epoch 6/20\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 1.0844 - accuracy: 0.7187 - val_loss: 0.6877 - val_accuracy: 0.8131\n",
            "Epoch 7/20\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.9413 - accuracy: 0.7565 - val_loss: 0.6834 - val_accuracy: 0.8173\n",
            "Epoch 8/20\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.8410 - accuracy: 0.7808 - val_loss: 0.6942 - val_accuracy: 0.8172\n",
            "Epoch 9/20\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.7659 - accuracy: 0.7987 - val_loss: 0.6930 - val_accuracy: 0.8183\n",
            "Epoch 10/20\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.7074 - accuracy: 0.8148 - val_loss: 0.6845 - val_accuracy: 0.8189\n",
            "Epoch 11/20\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.6895 - accuracy: 0.8184 - val_loss: 0.6884 - val_accuracy: 0.8201\n",
            "Epoch 12/20\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.6252 - accuracy: 0.8342 - val_loss: 0.6623 - val_accuracy: 0.8226\n",
            "Epoch 13/20\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.6126 - accuracy: 0.8372 - val_loss: 0.6669 - val_accuracy: 0.8246\n",
            "Epoch 14/20\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.5590 - accuracy: 0.8469 - val_loss: 0.6585 - val_accuracy: 0.8257\n",
            "Epoch 15/20\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.5349 - accuracy: 0.8548 - val_loss: 0.6548 - val_accuracy: 0.8255\n",
            "Epoch 16/20\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.5183 - accuracy: 0.8559 - val_loss: 0.6659 - val_accuracy: 0.8224\n",
            "Epoch 17/20\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.5058 - accuracy: 0.8613 - val_loss: 0.6492 - val_accuracy: 0.8224\n",
            "Epoch 18/20\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.4753 - accuracy: 0.8643 - val_loss: 0.6393 - val_accuracy: 0.8244\n",
            "Epoch 19/20\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.4690 - accuracy: 0.8671 - val_loss: 0.6519 - val_accuracy: 0.8256\n",
            "Epoch 20/20\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.4420 - accuracy: 0.8760 - val_loss: 0.6356 - val_accuracy: 0.8255\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqFAAug_hqBz",
        "outputId": "1037a8ce-9d5e-44fe-f80f-157f8177c8d3"
      },
      "source": [
        "l,a = mm2.evaluate([X_test,X_test], y_test)\n",
        "l, a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.6564 - accuracy: 0.8250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.656421422958374, 0.824999988079071)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "Jt5_Vmlwh3r5",
        "outputId": "a250b98a-78c3-482f-c5b9-ebcf7a1be0bf"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(mm2_history.history['accuracy'])\n",
        "plt.plot(mm2_history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(mm2_history.history['loss'])\n",
        "plt.plot(mm2_history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3gc1dX48e+RtOq9uMq2bONKs0E2PaFjOoSE2ATS3sRpJCQheQM/Sgh5kze9vqQAIUAINp044EKJISFgXLADuBdsFTdZsnqXzu+PGdlreSWvLc3OSns+z7PPTtvdo9HuPXPvnbkjqooxxpjYFed3AMYYY/xlicAYY2KcJQJjjIlxlgiMMSbGWSIwxpgYZ4nAGGNinCUCE1NE5GER+Z8wt90uIhd6HZMxfrNEYIwxMc4SgTEDkIgk+B2DGTwsEZio4zbJfFtE3hWRBhH5k4gMFZFFIlInIq+ISE7Q9leJyFoRqRaR10RkStC66SLyjvu6J4Dkbp91hYiscV/7poicFGaMl4vIahGpFZFSEbmn2/qz3ferdtd/2l2eIiI/F5EdIlIjIm+4y84VkbIQ++FCd/oeEXlaRB4TkVrg0yIyU0Tecj9jl4j8n4gkBr3+eBF5WUSqRGSPiPw/ERkmIo0ikhe03SkiUiEigXD+djP4WCIw0eo64CJgInAlsAj4f0ABzvf2awAiMhGYB3zdXbcQ+LuIJLqF4vPAX4Bc4Cn3fXFfOx14CPgCkAf8EVggIklhxNcAfBLIBi4HviQi17jvO8aN97duTNOANe7rfgacCpzpxvTfQGeY++Rq4Gn3M/8KdADfAPKBM4ALgC+7MWQArwCLgRHAccCrqrobeA24Puh9bwLmq2pbmHGYQcYSgYlWv1XVPapaDvwLeFtVV6tqM/AcMN3d7uPAi6r6sluQ/QxIwSloTwcCwK9UtU1VnwZWBH3GXOCPqvq2qnao6iNAi/u6Xqnqa6r6nqp2quq7OMnow+7qG4BXVHWe+7mVqrpGROKAzwK3qGq5+5lvqmpLmPvkLVV93v3MJlVdparLVLVdVbfjJLKuGK4Adqvqz1W1WVXrVPVtd90jwI0AIhIPzMFJliZGWSIw0WpP0HRTiPl0d3oEsKNrhap2AqXASHdduR46suKOoOkxwK1u00q1iFQDo9zX9UpEThORpW6TSg3wRZwjc9z32BriZfk4TVOh1oWjtFsME0XkBRHZ7TYX/TCMGAD+BkwVkbE4ta4aVV1+jDGZQcASgRnoduIU6ACIiOAUguXALmCku6zL6KDpUuAHqpod9EhV1XlhfO7jwAJglKpmAX8Auj6nFBgf4jX7gOYe1jUAqUF/RzxOs1Kw7kMF/x7YAExQ1UycprPgGMaFCtytVT2JUyu4CasNxDxLBGagexK4XEQucDs7b8Vp3nkTeAtoB74mIgER+QgwM+i1DwBfdI/uRUTS3E7gjDA+NwOoUtVmEZmJ0xzU5a/AhSJyvYgkiEieiExzaysPAb8QkREiEi8iZ7h9EpuAZPfzA8CdwJH6KjKAWqBeRCYDXwpa9wIwXES+LiJJIpIhIqcFrX8U+DRwFZYIYp4lAjOgqepGnCPb3+IccV8JXKmqraraCnwEp8CrwulPeDbotSuBzwP/B+wHtrjbhuPLwL0iUgfcjZOQut63BLgMJylV4XQUn+yu/hbwHk5fRRXwYyBOVWvc93wQpzbTABxyFlEI38JJQHU4Se2JoBjqcJp9rgR2A5uB84LW/xunk/odVQ1uLjMxSOzGNMbEJhH5B/C4qj7odyzGX5YIjIlBIjIDeBmnj6PO73iMv6xpyJgYIyKP4Fxj8HVLAgasRmCMMTHP0xqBiMwSkY0iskVEbguxfoyIvCrOUAKviUihl/EYY4w5nGc1Avc86E04Zy6U4ZwlMUdV1wVt8xTwgqo+IiLnA59R1Zt6e9/8/HwtKiryJGZjjBmsVq1atU9Vu1+bAoCXIxjOBLao6jYAEZmPM1bKuqBtpgLfdKeX4owL06uioiJWrlzZz6EaY8zgJiI9nibsZdPQSA69JL7MXRbsPzjneQNcC2QEj4pojDHGe36fNfQt4MMishpnsKxynBEVDyEic0VkpYisrKioiHSMxhgzqHmZCMpxxnzpUuguO0BVd6rqR1R1OnCHu6y6+xup6v2qWqyqxQUFIZu4jDHGHCMv+whWABPcEQ7LgdkcOh4LIpKPM15LJ3A7zjgsR62trY2ysjKam5v7GHJ0S05OprCwkEDA7h9ijOk/niUCVW0XkZuBJUA88JCqrhWRe4GVqroAOBf4XxFR4J/AV47ls8rKysjIyKCoqIhDB5ocPFSVyspKysrKGDt2rN/hGGMGEU/ve6qqC3HuGBW87O6g6adx7rjUJ83NzYM6CQCICHl5eVgfiTGmv/ndWdxvBnMS6BILf6MxJvI8rREYY4wJn6pS39JOdWMb+xtb2d/YRnVjK/sbnOkLpgzhpMLsfv9cSwT9oLq6mscff5wvf/nLR/W6yy67jMcff5zs7P7/xxpj/NXS3kFNYxvVTW1UuwV6VwFf1dhKdYMzHVzo1zS10tbR82gPBRlJlgiiVXV1Nb/73e8OSwTt7e0kJPS8ixcuXNjjOmOM/zo7lbqWduqa26hrbqem6WCB3lXA1zS58+6yGrdQb2o77JKoAwLxQk5qIjmpiWSnBhhfkE5OWoDs1ERyUrueg6cDZKUESIj3pjXfEkE/uO2229i6dSvTpk0jEAiQnJxMTk4OGzZsYNOmTVxzzTWUlpbS3NzMLbfcwty5c4GDw2XU19dz6aWXcvbZZ/Pmm28ycuRI/va3v5GSkuLzX2bMwNba3klN08HCuq65ndrmNmqbDxbuXc+1TV3zB5fVt7bT23BsgXghOzWR7JQA2akBRmancPyIzAMFeJa7PDvl4HROWiJpifFR1ec36BLB9/6+lnU7a/v1PaeOyOS7Vx7f4/of/ehHvP/++6xZs4bXXnuNyy+/nPfff//AaZ4PPfQQubm5NDU1MWPGDK677jry8g4dSWPz5s3MmzePBx54gOuvv55nnnmGG2+8sV//DmMGqraOTirrW6kOOvo+cCQe4si868i9obXno3KAhDghIzmBzJQAGckJZCQFGJOXSkZygMyUBOc5OcFZl3ywUM9OdaZTAtFVoB+rQZcIosHMmTMPOdf/N7/5Dc899xwApaWlbN68+bBEMHbsWKZNmwbAqaeeyvbt2yMWrzF+UFVqmtqoqGtxHvXO896u+aDlVQ2tPb5PQpyQ7TadZKcmMjwrmcnDMw4psLNSnEdmilOwZyYHyEgOkByIGxQFeV8NukTQ25F7pKSlpR2Yfu2113jllVd46623SE1N5dxzzw15BXRSUtKB6fj4eJqamiISqzH9qbW9k6qGViobnMK7sr6VyoZWqtz57gV8qI7RxIQ4hmQkUZCRxJi8VIqLcijISCI/PYncNKcZJstteslOCZAaZc0sA9GgSwR+yMjIoK4u9B3/ampqyMnJITU1lQ0bNrBs2bIIR2dM37R1dFK2v4nSqkb2uUfnlQ2tVLmFfFehX1XfSl1Le8j3iI9zOkcL3AJ+wtAMZzo96cCyrkdGUoIV7BFmiaAf5OXlcdZZZ3HCCSeQkpLC0KFDD6ybNWsWf/jDH5gyZQqTJk3i9NNP9zFSY0JrbuugpKqR7fsanOfKBnZUNrKjspHy6iY6Og89cg/EC7lpieSmJZGXlsionFRy0xLJT3eW5aYlkpee6DynJZKZHCAuzgr3aDXg7llcXFys3W9Ms379eqZMmeJTRJEVS3+r6V+1zW2UuIW7U9AfLOx31x7aXJmdGmBMbipj8tIoyktldF4ao3NTGZKRRG56oh21D0AiskpVi0OtsxqBMQNcZ6dS1djK7ppmdtc0s6u2mT01zeyqaWZPbTO7aprYU9tCfbdmm4KMJIryUjnruHyK8lIZk5/mFv6pZKcm+vTXGD9YIjAmynV0Kh/sa2DTnjp2Vjc5BX5t84HnPbXNh3W6xscJQzKSGJaVzMShGXxoYgHDMpMZk+cc5Y/OTSUtyX7+xmHfBGOiSGNrOxt217FuZy3rdtWybmctG3bX0tzWeWCb5EAcw7NSGJqZxIyiXIZmJjM8K/nA87CsZPLTk4i3NnkTJksExvhAVamoa2GtW9iv21XL+p21fFDZcOBK1szkBKaOyOSGmWOYOiKTycMyGJWTSmaKtc+b/mWJwBiPNbV2sG1fPVv21h84yl+/q5Z99QcvkhqVm8LU4ZlcPW0kU4ZnMHVEJiOzU5wCv6MNWhugrQGa9kFdM7Q1OY/25t6f25qgvQnamp1lHW3Q2eY+twfNtwct7z7ffvAZQASQw597WyeAxEFiOiRluI/MoOlQ892XpYPE9+E/odDeEmI/Nbr7p+nIzx3uPuloPbhfDky3Hlzfte8OTLc6+zTYgWQu3eaDl3Hoskt+ANP7f8QBSwTGhKIK2gmdHaAdB6cP+cEfLAC0o43qugZ2VtWxe38de/bXsbe6nn01ddQ2NJEo7QRoJz2ulYvSlc9kK8OGd5Cf2E52oI3EjiZobYSt9bCh0ZlurXcKqY6er6rtVXwiJKRAIBkCKZCQDPEBiAscfE5MDZpPCFqfcOh28QnO+q59g3Z75tDpUNtoh/N3tdRCSx00VsL+7c50S52T6KJR1z5MSHb2aXzAeY5LCJoPQCD14HScu028u03XvuwueN+Fsyx3vBd/oSWC/nCsw1AD/OpXv2Lu3LmkpqZ6EFmEdbRD035oqoLGqsOfW2oPfqG7Hw2FWnbYEZIeenTa69FrD0e92uEW7p3udOehBX3Xeo7utGoBctzHYde2dz8BpwloCUBimvMIpB6cTisIvTyQ6hTagVSnQOoq2A88p7qFVVChFdeXo2cfdLQ7ya8rMXQljAPP9c7/qS8Skrvtp+7P7j4NpDjLEpK6fQ8HJ0sE/aCnYajD8atf/Yobb7wxehNBayNU74D9O6CmNHQB31QFjfuhpabn94kLQHKW0zzQ29FPr0dI9HLUGrQ8IRHi0kIc5Qacz4+Ld54l3p2Od37sXdNB6xvblZL9LWyvamLH/mb2NHTS0hlPKwm0azwpKcnkZaYxJCudITmZDM/JYHheJnkZacQlBA49Yuw6Ag+kOTGaQ8UnQEq28zARZYmgHwQPQ33RRRcxZMgQnnzySVpaWrj22mv53ve+R0NDA9dffz1lZWV0dHRw1113sWfPHnbu3Ml5551Hfn4+S5cujXzwHW1QU3awsD/keTs0hLhHclImpORAai6k5ELeeOe5az4199D1qblO2/AAOLKqaWpj+QdVvLl1H29trWTDbmfokPSkBIqLcpg8LJMpBWmMH5LO+IJ0slJCVPeNGWA8TQQiMgv4NRAPPKiqP+q2fjTwCJDtbnObe8P7Y7foNtj9Xp/e4jDDToRLf9Tj6uBhqF966SWefvppli9fjqpy1VVX8c9//pOKigpGjBjBiy++CDhjEGVlZfGLX/yCpUuXkp+f378xB1OF/R9A2SqncK/efrCwryl3mkO6SDxkFUJOEUy6FLLHONPZYyB7FKTmhW7rHKAaW9tZuX0/b26t5K2t+3ivvIZOhaSEOGYU5fLtS0Zw5vg8ThyZ5dlNQYzxm2eJQETigfuAi4AyYIWILFDVdUGb3Qk8qaq/F5GpwEKgyKuYIuGll17ipZdeYvr06QDU19ezefNmzjnnHG699Va+853vcMUVV3DOOed4F4QqVG2D7W84jx3/htryg+vThzoF+6jT4KQit7Af4zxnjnSq6INUS3sHa0qq3YK/ktWl+2nrUBLihOmjs7n5/AmcOT6P6aOzSUoYYG3sxhwjL3/xM4EtqroNQETmA1cDwYlAgUx3OgvY2edP7eXIPRJUldtvv50vfOELh6175513WLhwIXfeeScXXHABd999d399KFRuhe3/cgr97W9A3S5nXdoQKDobis6C0WdA7jinIyxGtLR38G5ZDW9vq+TtD6pYsb2K5rZORODEkVl89uyxnDk+n+IxOXalrYlZXn7zRwKlQfNlwGndtrkHeElEvgqkAReGeiMRmQvMBRg9enS/B9pXwcNQX3LJJdx111184hOfID09nfLycgKBAO3t7eTm5nLjjTeSnZ3Ngw8+eMhrj6ppSBX2bYYdbxw86q/f46xLH+oW/GfDmLMhf8KAaJvvL02tHawu2c+yD6p4e1slq0uraW13zjSZNDSD2TNGc+b4PE4bm0dW6uBp4jKmL/w+BJoDPKyqPxeRM4C/iMgJqoeeI6aq9wP3gzP6qA9x9ip4GOpLL72UG264gTPOOAOA9PR0HnvsMbZs2cK3v/1t4uLiCAQC/P73vwdg7ty5zJo1ixEjRvTeWdzpnprZsA9+NhEa9jrLM4bD2A/BmLOg6Byn4zaGCv665jZW7djP2x9UsfyDKt4tq6atQ4kTOH5EFjedPoaZY3OZWZRLTpqdqWNMKJ4NQ+0W7Peo6iXu/O0Aqvq/QdusBWapaqk7vw04XVX39vS+MTcMtapzimbdTuhsZ31pFVPK5h886s8dF1MFf3VjKyu27z/Q1LN2p9O5mxAnnFSYxcyxeZw2LpdTx+SQmWxH/MZ08WsY6hXABBEZC5QDs4Ebum1TAlwAPCwiU4BkIMT5ijGqtcE5tbOt0Tn3PHcc1JTAdQ/4HVlE1TS18dTKUp55p5wNu2tRdW5nOH1UNjefdxynjXM6d1MT/a7gGjMwefbLUdV2EbkZWIJzauhDqrpWRO4FVqrqAuBW4AER+QZOx/GndaDdKccLHW1ODaCxyrkgKnuMc15+DB35A2zZW8fDb27nmVXlNLV1cOqYHL554UROG5fHSYVZJAfsrB5j+oOnh1DuNQELuy27O2h6HXBWP33WwB+RUTudPoC63c502hDIGHZgqIBYyJGdncprm/by539v51+b95GYEMfVJ4/gU2cWccLILL/DM2ZQGhR16eTkZCorK8nLyxu4yaClzmkGam92RlrMLHTGPnGpKpWVlSQnJ/fyJgNXXXMbT60s49G3trO9spGhmUl86+KJzJk5mrz0JL/DM2ZQGxSJoLCwkLKyMioqBmD3Qmc7NFU7/QBxCU4TUKAN9n5w2KbJyckUFhb6EKR3tlXU8+hbO3hqZSkNrU7zz60XT2LWCcMI2JW8xkTEoEgEgUCAsWPH+h3G0Wlrgn//Bt74pTN/zq1w5lcPqQUMVp2dyj83V/Dwm9t5bWMFgXjhypOc5p+TR9mAY8ZE2qBIBAOKKmx4EZbcDtUlMPUauPh/nHF8Brn6lnaefaeMh9/czraKBgoykvjGhROZc9oohmQM/gRoTLSyRBBJFZtg8Xdg6z+gYAp8cgGM+7DfUXmuraOTh/+9nd+8upm6lnZOLsziVx+fxmUnDicxwZp/jPGbJYJI2bAQnrzJuR5g1o9hxucG9eBuXVbt2M8dz73Hht11nD95CF89/zimj87xOyxjTJDBXxJFg7ZmWPQdyJ8En/wbpBf4HZHnqhtb+fHijcxbXsKIrGTuv+lULj5+mN9hGWNCsEQQCW//3rkiOAaSgKry3OpyfvDieqqb2vj8OWP5+oUTbWRPY6KY/Tq9Vl8B//oFTJwF4871OxpPbdlbz53Pv8eybVVMH53NX645kakjMo/8QmOMrywReO21/3XGDLro+35H4pnmtg7uW7qFP7y+lZRAPD+89kRmzxhFXNwAvbjPmBhjicBLezfAqoeh+LNQMNHvaDzx+qYK7nr+fUqqGvnI9JHcftkUCjLsSmBjBhJLBF56+S7npu3n3uZ3JP1uT20z976wjhff3cW4/DQe/9xpnHmch/ddNsZ4xhKBV7b+Aza/BBfdC2mDp4Ds6FQeW7aDny3ZSEtHJ9+8aCJf+PA4u7+vMQOYJQIvdHbAkjud4aNnHn7v4oHq3bJq7njufd4rr+GcCfl8/+oTKMpP8zssY0wfWSLwwurHYO9a+OifB83YQQ//+wPufWEdeelJ/HbOdK44afjAHenVGHMISwT9raUOlv4ACmfC8df6HU2/uG/pFn66ZCMXTx3Kz64/2W4BacwgY4mgv/3711C/Bz7+1wF/RzFV5SdLNvL717Zy7fSR/PSjJ5FgQ0MbM+hYIuhPNWXw5v/BCdfBqBl+R9MnnZ3KPX9fy6Nv7eATp43m+1efYNcFGDNIWSLoT69+37nF5AXf9TuSPmnv6OS2Z9/j6VVlzP3QOG6/dLL1BxgziHlazxeRWSKyUUS2iMhhJ9OLyC9FZI372CQi1V7G46nyd+Dd+XD6lyBnjN/RHLPW9k5umb+Gp1eV8Y0LJ1oSMCYGeFYjEJF44D7gIqAMWCEiC9wb1gOgqt8I2v6rwHSv4vGUKrx0J6Tmwznf9DuaY9bc1sGXHlvF0o0V3Hn5FD53zji/QzLGRICXNYKZwBZV3aaqrcB84Opetp8DzPMwHu9seAF2/BvOux2Ss/yO5pjUt7TzmT+v4LVNFfzw2hMtCRgTQ7xMBCOB0qD5MnfZYURkDDAW+EcP6+eKyEoRWRl1N6hvb4WX73buNXDKp/2O5pjUNLZx05/eZvn2Kn55/TRuOG203yEZYyIoWs4FnA08raodoVaq6v2qWqyqxQUFUTae/4oHoWqbc9/hAXjHsX31Lcx+YBlry2u574ZTuGZ6yFxtjBnEvCy5yoHgO7IXustCmQ18xcNYvNFYBa//GMadBxMu8juao7a7pplPPLiM8uomHvhUMR+eGGVJ1hgTEV7WCFYAE0RkrIgk4hT2C7pvJCKTgRzgLQ9j8cY/fwrNNU5tYICdWVNS2cjH/vgme2pbePSzp1kSMCaGeZYIVLUduBlYAqwHnlTVtSJyr4hcFbTpbGC+qqpXsXiicissfwBOuQmGneB3NEdly946PvbHN6lrbuevnzuNmWNz/Q7JGOMjTxu1VXUhsLDbsru7zd/jZQyeefluiE+E8+70O5KjsnZnDTf9aTlxIsyfezqTh9mtJI2JddHSWTywbH/DOWX07G9AxlC/ownbqh37mXP/MpIT4njqi2dYEjDGADbExNHr7IQld0DGCDhj4PRvv1dWw01/epshGUk89rnTKMxJ9TskY0yUsERwtN57EnatgWv/CIkDozDt7FTufP490pMSePILZzAkc3DcI8EY0z+saehotDbCq/fC8Glw4vV+RxO2Z1eX85+yGm67dLIlAWPMYaxGcDTeug9qy+EjD0DcwMih9S3t/GTxBk4elc010+xiMWPM4QZGaRYN6vbAG7+EyVdA0Vl+RxO23y3dwt66Fr575VS7n4AxJiRLBOFa+RC0NcJF9/odSdhKKht58I0PuHb6SE4ZneN3OMaYKGWJIFwbF8KomZA33u9IwvbDheuJF+E7syb7HYoxJopZIghHTTnsfhcmXep3JGF7c+s+Fq/dzVfOG8+wLOsgNsb0zBJBODYtdp4nDoxE0N7Ryb1/X8fI7BS7r4Ax5ogsEYRj02LIKYKCSX5HEpb5K0rZsLuOOy6fQnIg3u9wjDFRzhLBkbQ2wLbXndrAABhhtKaxjZ+/tJGZY3O59IRhfodjjBkALBEcybbXoKMFJs3yO5Kw/PrVzVQ3tfHdK6faTeeNMWGxRHAkGxdBUiaMPtPvSI5oy956Hn1rO7NnjOb4EQPz3snGmMizRNCbzk7YtASOuwASEv2O5oj+58V1pATiufXiiX6HYowZQCwR9GbnamjYOyDOFlq6YS+vbazglgsnkJ+e5Hc4xpgBxBJBbzYtAomL+vsRt7Z38v0X1zEuP41PnlHkdzjGmAHGEkFvNi6GUadDanTfyvHRt7azraKBO6+YQmKC/UuNMUfHSo2eVJfAnvei/myhyvoWfv3qZj40sYDzJg3xOxxjzABkiaAnm5Y4z1HeP/DzlzfR2NrB3VdMsdNFjTHHxNNEICKzRGSjiGwRkdt62OZ6EVknImtF5HEv4zkqGxdB7jjIn+B3JD1at7OW+ctL+OQZYzhuSIbf4RhjBijPbkwjIvHAfcBFQBmwQkQWqOq6oG0mALcDZ6nqfhGJjraNljrY/i+Y8fmovZpYVbn3hbVkpQT4+gV2uqgx5th5WSOYCWxR1W2q2grMB67uts3ngftUdT+Aqu71MJ7wbV0KHa1R3T+w+P3dLNtWxTcvnkRWasDvcIwxA5iXiWAkUBo0X+YuCzYRmCgi/xaRZSISsuQVkbkislJEVlZUVHgUbpBNiyE5C0af4f1nHYPmtg5+sHA9k4ZmMGfGKL/DMcYMcGElAhF5VkQuF5H+ThwJwATgXGAO8ICIZHffSFXvV9ViVS0uKCjo5xC66exwrya+COKj80j7T298QNn+Ju6+cioJ8dbfb4zpm3BLkd8BNwCbReRHIhLOeMzlQPDhaqG7LFgZsEBV21T1A2ATTmLwT/kqaNwXtTeh2VPbzH1Lt3DJ8UM567h8v8MxxgwCYSUCVX1FVT8BnAJsB14RkTdF5DMi0tNh8wpggoiMFZFEYDawoNs2z+PUBhCRfJymom1H/Vf0p42LQOKd8YWi0I8Xb6C9Q7njsql+h2KMGSTCblcQkTzg08DngNXAr3ESw8uhtlfVduBmYAmwHnhSVdeKyL0icpW72RKgUkTWAUuBb6tq5TH+Lf1j02IYcyakRN/N3leX7OfZd8r5r3PGMjov1e9wjDGDRFinj4rIc8Ak4C/Alaq6y131hIis7Ol1qroQWNht2d1B0wp80334b/8O2LsOLv6B35EcprNT+d7f11GQkcRXzjvO73CMMYNIuNcR/EZVl4ZaoarF/RiPv7ruTRyF/QOL3t/NmtJqfvrRk0hP8uzyD2NMDAq3aWhq8Nk8IpIjIl/2KCb/bFwEeRMgb7zfkRzmL8u2Myo3hetOKfQ7FGPMIBNuIvi8qlZ3zbgXgH3em5B80lwL29+IyovIPtjXwLJtVcyeMZq4uOi80tkYM3CFmwjiJWhEM3f4iOi/ZdfR2PoP6GyLykHm5q8oIT5O+NipVhswxvS/cBubF+N0DP/Rnf+Cu2zw2LQYkrNh1Gl+R3KI1vZOnllVxvmThzAkM9nvcIwxg1C4ieA7OIX/l9z5l4EHPYnID11XE0+4GOKjqyP21fV72FffypyZNpSEMcYbYZV6qtoJ/N59DHhRUoQAABSjSURBVD6ly6GpKir7B+atKGV4VjIfnhgdA7MaYwafcMcamiAiT7v3DdjW9fA6uIjZtAjiEuC4C/2O5BClVY38a3MFHyseRbx1EhtjPBJuZ/GfcWoD7cB5wKPAY14FFXEbF8OYs5wRR6PIUyudwVuvL7ZOYmOMd8JNBCmq+iogqrpDVe8BLvcurAiq2gb7NkbdRWTtHZ08ubKMD08soDDHhpMwxngn3ETQ4g5BvVlEbhaRa4F0D+OKnI3uyU8To6t/4PVNFeyubWb2jNF+h2KMGeTCTQS3AKnA14BTgRuBT3kVVERtWgQFkyF3rN+RHGLe8lLy05O4YIp1EhtjvHXEROBePPZxVa1X1TJV/YyqXqeqyyIQn7eaa2DHm1FXG9hd08zSjXv5WHEhAbvxjDHGY0csZVS1Azg7ArFE3pZXoLM96voHnlpZSkenMttuQ2mMiYBwr55aLSILgKeAhq6FqvqsJ1FFysbFkJoHhTP8juSAzk7liZWlnDk+jzF5aX6HY4yJAeEmgmSgEjg/aJkCAzcRdLTD5pec2kBcvN/RHPDGln2U7W/iv2dN9jsUY0yMCPfK4s94HUjElb4NzdVR1z8wf0UJOakBLjl+qN+hGGNiRLh3KPszTg3gEKr62X6PKFI2LYK4AIw//8jbRsi++hZeXreHT55RRFJC9NRSjDGDW7hNQy8ETScD1wI7+z+cCNq4GIrOhuRMvyM54JlVZbR1qA0wZ4yJqLDOTVTVZ4IefwWuB454i0oRmSUiG0Vki4jcFmL9p0WkQkTWuI/PHf2fcAwqt0Ll5qg6W0hVeWJFKcVjcjhuSIbf4RhjYsixjrk8Aej1Sif3+oP7gIuAMmCFiCxQ1XXdNn1CVW8+xjiOzcZFznMU9Q+8/UEV2/Y18GW7Mb0xJsLC7SOo49A+gt049yjozUxgi6puc99jPnA10D0RRN7GRTBkKuSM8TuSA+YvLyEjOYHLTxzudyjGmBgTbtNQhqpmBj0mquozR3jZSKA0aL7MXdbddSLyrjvMdcjGcRGZKyIrRWRlRUVFOCH3rGk/lLwVVbWB6sZWFr6/m2unjyQl0TqJjTGRFe79CK4Vkayg+WwRuaYfPv/vQJGqnoRz17NHQm2kqverarGqFhcUFPTtEze/AtoBky7r2/v0o+dWl9Pa3mkDzBljfBHuQDbfVdWarhlVrQa+e4TXlAPBR/iF7rIDVLVSVVvc2QdxBrTz1qZFkFYAI73/qHCoKvOXl3JyYRZTR0TPGUzGmNgRbiIItd2R+hdWABNEZKyIJAKzgQXBG4hIcIP4VcD6MOM5Nh1tTo1gwiUQFx2Dua0urWbjnjpmz7TagDHGH+GeNbRSRH6BcxYQwFeAVb29QFXbReRmYAkQDzykqmtF5F5gpaouAL4mIlfh3PmsCvj0MfwN4St5C1pqourexPOXl5CaGM+VJ4/wOxRjTIwKNxF8FbgLeALn7KGXcZJBr1R1IbCw27K7g6ZvB24PN9g+27gY4hNh3HkR+8je1DW38ff/7OLqaSNITzrWM3mNMaZvwh1rqAE47IKwAUXV6R8Y+yFIio6bq/1tzU6a2jqsWcgY46twzxp6WUSyg+ZzRGSJd2F5YN9m5/7EUXTa6PwVJUwelsHJhVlH3tgYYzwSbo9pvnumEACqup8jXFkcdTZF19XE75fX8H55LXNmjkZE/A7HGBPDwm2Y7hSR0apaAiAiRYQYjTSqTb4CkrMhOzoGdJu3vISkhDiumRbqGjtjjImccBPBHcAbIvI6IMA5wFzPovJC3njnEQUaW9v525qdXH7icLJSA36HY4yJceF2Fi8WkWKcwn818DzQ5GVgg9kL7+6ivqXdOomNMVEh3EHnPgfcgnN18BrgdOAtDr11pQnT/OUljC9IY0ZRjt+hGGNM2J3FtwAzgB2qeh4wHaju/SUmlE176ninpNo6iY0xUSPcRNCsqs0AIpKkqhuASd6FNXjNW15CYnwcHzml0O9QjDEGCL+zuMy9juB54GUR2Q/s8C6swam5rYPnVpdz8fFDyU1L9DscY4wBwu8svtadvEdElgJZwGLPohqklqzdTXVjG3Osk9gYE0WOeoAbVX3di0BiwbzlJYzOTeWMcXl+h2KMMQdEx1jMMWBbRT3LtlXx8RmjiIuzTmJjTPSwRBAhT6woJT5O+Nip1klsjIkulggioLW9k6dXlXHB5CEMyUz2OxxjjDmEJYIIeGX9HiobWq2T2BgTlSwRRMC85SWMyErmQxML/A7FGGMOY4nAY6VVjbyxZR/XzxhFvHUSG2OikCUCjz2xohQBri+OjuGvjTGmO0sEHmrv6OSpVaV8eGIBI7JT/A7HGGNC8jQRiMgsEdkoIltEpMd7HovIdSKi7lDXg8bSjRXsqW2x4aaNMVHNs0QgIvHAfcClwFRgjohMDbFdBs7opm97FYtf5i8vYUhGEudPHlh39TTGxBYvawQzgS2quk1VW4H5wNUhtvs+8GOg2cNYIm5XTRNLN+7lY8WFBOKtBc4YE728LKFGAqVB82XusgNE5BRglKq+2NsbichcEVkpIisrKir6P1IPPLmijE6Fjxdbs5AxJrr5dqgqInHAL4Bbj7Stqt6vqsWqWlxQEP3n4nd0Kk+uLOXs4/IZnZfqdzjGGNMrLxNBORB8zmShu6xLBnAC8JqIbMe5/eWCwdBh/K/NFZRXNzF7pp0yaoyJfl4mghXABBEZKyKJwGxgQddKVa1R1XxVLVLVImAZcJWqrvQwpoiYv7yU3LRELpo61O9QjDHmiDxLBKraDtwMLAHWA0+q6loRuVdErvLqc/22t66ZV9bv4aOnFpKUEO93OMYYc0RHfWOao6GqC4GF3Zbd3cO253oZS6Q8vaqM9k7l4zOsWcgYMzDYeY39qLNTeWJFKTPH5jK+IN3vcIwxJiyWCPrRsm2V7KhsZI51EhtjBhBLBP1o3opSMpMTuPSE4X6HYowxYbNE0E+qGlpZ8v5uPnJKIckB6yQ2xgwclgj6ybPvlNHa0Wl3ITPGDDiWCPqBqjJveQnTR2czaViG3+EYY8xRsUTQD1bu2M/WigbmzLDagDFm4LFE0A/mLS8hPSmBK062TmJjzMBjiaCPapraWPjeLq6eNoLURE+vzzPGGE9YIuijv60pp7nNOomNMQOXJYI+UFUef7uEE0ZmcsLILL/DMcaYY2KJoA/+U1bDht11zLZOYmPMAGaJoA/mLy8hJRDP1dNG+B2KMcYcM0sEx6i+pZ0F/9nJFScNJyM54Hc4xhhzzCwRHKO//2cnja0dzDnNmoWMMQObJYJjNG95CZOGZjB9VLbfoRhjTJ9YIjgGa3fW8G5ZDbNnjkJE/A7HGGP6xBLBMZi/vJTEhDiunT7S71CMMabPLBEcpabWDp5fU85lJwwjOzXR73CMMabPPE0EIjJLRDaKyBYRuS3E+i+KyHsiskZE3hCRqV7G0x9efG8Xdc3tdiWxMWbQ8CwRiEg8cB9wKTAVmBOioH9cVU9U1WnAT4BfeBVPf5m3vIRxBWnMHJvrdyjGGNMvvKwRzAS2qOo2VW0F5gNXB2+gqrVBs2mAehhPn23aU8eqHfuZPcM6iY0xg4eXw2WOBEqD5suA07pvJCJfAb4JJALnh3ojEZkLzAUYPdq/Jpn5y0sJxAvXnVLoWwzGGNPffO8sVtX7VHU88B3gzh62uV9Vi1W1uKCgILIBuprbOnh2dRkXTx1GXnqSLzEYY4wXvEwE5cCooPlCd1lP5gPXeBhPnyx6fxfVjW3WSWyMGXS8TAQrgAkiMlZEEoHZwILgDURkQtDs5cBmD+M5Zh2dyu+WbmXCkHTOHJ/ndzjGGNOvPOsjUNV2EbkZWALEAw+p6loRuRdYqaoLgJtF5EKgDdgPfMqrePpi4Xu72Ly3nt/OmU5cnHUSG2MGF0/vraiqC4GF3ZbdHTR9i5ef3x86OpXfvLqZCUPSuexEuyexMWbw8b2zONp11Qa+dsEE4q02YIwZhCwR9MJqA8aYWGCJoBdWGzDGxAJLBD2w2oAxJlZYIuiB1QaMMbHCEkEIVhswxsQSSwQhWG3AGBNLLBF0Y7UBY0yssUTQjdUGjDGxxhJBEKsNGGNikSWCIFYbMMbEIksELqsNGGNilSUCl9UGjDGxyhIBVhswxsQ2SwRYbcAYE9tiPhFYbcAYE+tiPhFYbcAYE+tiOhFYbcAYY2I8EVhtwBhjPE4EIjJLRDaKyBYRuS3E+m+KyDoReVdEXhWRMV7GE8xqA8YY4/AsEYhIPHAfcCkwFZgjIlO7bbYaKFbVk4CngZ94FU93VhswxhiHlzWCmcAWVd2mqq3AfODq4A1UdamqNrqzy4BCD+M5wGoDxhhzkJeJYCRQGjRf5i7ryX8BizyM5wCrDRhjzEEJfgcAICI3AsXAh3tYPxeYCzB69Og+fZbVBowx5lBe1gjKgVFB84XuskOIyIXAHcBVqtoS6o1U9X5VLVbV4oKCgj4FZbUBY4w5lJeJYAUwQUTGikgiMBtYELyBiEwH/oiTBPZ6GAtgtQFjjAnFs0Sgqu3AzcASYD3wpKquFZF7ReQqd7OfAunAUyKyRkQW9PB2/cJqA8YYczhP+whUdSGwsNuyu4OmL/Ty84NZbcAYY0KLmSuLrTZgjDGhxUwiSEuK56KpQ602YIwx3UTF6aORcP7koZw/eajfYRhjTNSJmRqBMcaY0CwRGGNMjLNEYIwxMc4SgTHGxDhLBMYYE+MsERhjTIyzRGCMMTHOEoExxsQ4UVW/YzgqIlIB7DjGl+cD+/oxnP5m8fWNxdd30R6jxXfsxqhqyHH8B1wi6AsRWamqxX7H0ROLr28svr6L9hgtPm9Y05AxxsQ4SwTGGBPjYi0R3O93AEdg8fWNxdd30R6jxeeBmOojMMYYc7hYqxEYY4zpxhKBMcbEuEGZCERklohsFJEtInJbiPVJIvKEu/5tESmKYGyjRGSpiKwTkbUickuIbc4VkRoRWeM+7g71Xh7GuF1E3nM/e2WI9SIiv3H337sickoEY5sUtF/WiEitiHy92zYR338i8pCI7BWR94OW5YrIyyKy2X3O6eG1n3K32Swin4pQbD8VkQ3u/+85Ecnu4bW9fhc8jvEeESkP+j9e1sNre/29exjfE0GxbReRNT28NiL7sE9UdVA9gHhgKzAOSAT+A0ztts2XgT+407OBJyIY33DgFHc6A9gUIr5zgRd83Ifbgfxe1l8GLAIEOB1428f/9W6cC2V83X/Ah4BTgPeDlv0EuM2dvg34cYjX5QLb3OccdzonArFdDCS40z8OFVs43wWPY7wH+FYY34Fef+9exddt/c+Bu/3ch315DMYawUxgi6puU9VWYD5wdbdtrgYecaefBi4QkYjc0V5Vd6nqO+50HbAeGBmJz+5HVwOPqmMZkC0iftwM+gJgq6oe65Xm/UZV/wlUdVsc/D17BLgmxEsvAV5W1SpV3Q+8DMzyOjZVfUlV293ZZUBhf37m0eph/4UjnN97n/UWn1t2XA/M6+/PjZTBmAhGAqVB82UcXtAe2Mb9MdQAeRGJLojbJDUdeDvE6jNE5D8iskhEjo9oYKDASyKySkTmhlgfzj6OhNn0/OPzc/91Gaqqu9zp3UCom2ZHw778LE4NL5QjfRe8drPbfPVQD01r0bD/zgH2qOrmHtb7vQ+PaDAmggFBRNKBZ4Cvq2ptt9Xv4DR3nAz8Fng+wuGdraqnAJcCXxGRD0X4849IRBKBq4CnQqz2e/8dRp02gqg7V1tE7gDagb/2sImf34XfA+OBacAunOaXaDSH3msDUf97GoyJoBwYFTRf6C4LuY2IJABZQGVEonM+M4CTBP6qqs92X6+qtapa704vBAIikh+p+FS13H3eCzyHU/0OFs4+9tqlwDuquqf7Cr/3X5A9XU1m7vPeENv4ti9F5NPAFcAn3ER1mDC+C55R1T2q2qGqncADPXy2r99Ft/z4CPBET9v4uQ/DNRgTwQpggoiMdY8aZwMLum2zAOg6O+OjwD96+iH0N7c98U/AelX9RQ/bDOvqsxCRmTj/p4gkKhFJE5GMrmmcTsX3u222APike/bQ6UBNUBNIpPR4FObn/usm+Hv2KeBvIbZZAlwsIjlu08fF7jJPicgs4L+Bq1S1sYdtwvkueBljcL/TtT18dji/dy9dCGxQ1bJQK/3eh2Hzu7faiwfOWS2bcM4muMNddi/Olx4gGadJYQuwHBgXwdjOxmkieBdY4z4uA74IfNHd5mZgLc4ZEMuAMyMY3zj3c//jxtC1/4LjE+A+d/++BxRH+P+bhlOwZwUt83X/4SSlXUAbTjv1f+H0O70KbAZeAXLdbYuBB4Ne+1n3u7gF+EyEYtuC07be9R3sOotuBLCwt+9CBPffX9zv17s4hfvw7jG684f93iMRn7v84a7vXdC2vuzDvjxsiAljjIlxg7FpyBhjzFGwRGCMMTHOEoExxsQ4SwTGGBPjLBEYY0yMs0RgTAS5I6O+4HccxgSzRGCMMTHOEoExIYjIjSKy3B1D/o8iEi8i9SLyS3HuI/GqiBS4204TkWVBY/vnuMuPE5FX3MHv3hGR8e7bp4vI0+79AP4aqZFvjemJJQJjuhGRKcDHgbNUdRrQAXwC54rmlap6PPA68F33JY8C31HVk3CuhO1a/lfgPnUGvzsT58pUcEac/TowFefK07M8/6OM6UWC3wEYE4UuAE4FVrgH6yk4A8Z1cnBwsceAZ0UkC8hW1dfd5Y8AT7njy4xU1ecAVLUZwH2/5eqOTePe1aoIeMP7P8uY0CwRGHM4AR5R1dsPWShyV7ftjnV8lpag6Q7sd2h8Zk1DxhzuVeCjIjIEDtx7eAzO7+Wj7jY3AG+oag2wX0TOcZffBLyuzt3nykTkGvc9kkQkNaJ/hTFhsiMRY7pR1XUicifOXaXicEac/ArQAMx01+3F6UcAZ4jpP7gF/TbgM+7ym4A/isi97nt8LIJ/hjFhs9FHjQmTiNSrarrfcRjT36xpyBhjYpzVCIwxJsZZjcAYY2KcJQJjjIlxlgiMMSbGWSIwxpgYZ4nAGGNi3P8HXu5asakn2bkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "_GhF7HRpg5k1",
        "outputId": "25d84950-1e9c-45a6-e1a3-4356d8a8a7e8"
      },
      "source": [
        "o1=s1.get_layer(\"reqs1\").output\n",
        "o2=s2.get_layer(\"reqs2\").output\n",
        "output=tensorflow.keras.layers.concatenate([o1,o2])\n",
        "\n",
        "output=Activation('relu')(output)\n",
        "output2=Dropout(0.5)(output) # For reguralization\n",
        "output3=Dense(10,activation=\"softmax\", name=\"d1\")(output2)\n",
        "\n",
        "mm22=Model([s1.get_layer(\"s1\").input,s2.get_layer(\"s2\").input], output3)\n",
        "my_weights=teacher.get_layer('dense_2').get_weights()\n",
        "mm22.get_layer('d1').set_weights(my_weights)\n",
        "\n",
        "i=0\n",
        "for l in mm22.layers[:len(mm22.layers)-2]:\n",
        "    l.trainable=False\n",
        "#     print(l)\n",
        "\n",
        "# With finetune\n",
        "batch_size = 256\n",
        "mm22_history=mm22.fit([X_train,X_train], Y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=10,\n",
        "          verbose=1,\n",
        "          validation_data=([X_val,X_val], Y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-6740b5936a46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m           validation_data=([X_val,X_val], Y_val))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;31m# Legacy graph support is contained in `training_v1.Model`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m     \u001b[0mversion_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisallow_legacy_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_compile_was_called\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m     \u001b[0m_disallow_inside_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2590\u001b[0m     \u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2591\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2592\u001b[0;31m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[1;32m   2593\u001b[0m                          \u001b[0;34m'training/testing. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2594\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
            "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrzzCaYThyGp"
      },
      "source": [
        "l,a = mm22.evaluate([X_test,X_test], y_test)\n",
        "l, a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3n0VzZlg5k3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(mm22_history.history['accuracy'])\n",
        "plt.plot(mm22_history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(mm22_history.history['loss'])\n",
        "plt.plot(mm22_history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPpx-XYoh7hY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adrP-2NKruHh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJ0WYj8Krwas"
      },
      "source": [
        "# TCN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ1z088Hxo8N"
      },
      "source": [
        "## 1 Student"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5qA8beir1d_"
      },
      "source": [
        "s1 = define_model('s1')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnzUMRLvrzEz",
        "outputId": "c8843461-6eb2-4009-9845-66db89166d6e"
      },
      "source": [
        "history1=s1.fit(X_train,s1Train,\n",
        "          batch_size=256,\n",
        "          epochs=50,\n",
        "          verbose=1,\n",
        "          validation_data=(X_val,s1Val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "157/157 [==============================] - 6s 29ms/step - loss: 1.6353 - accuracy: 0.0023 - val_loss: 1.6285 - val_accuracy: 0.0252\n",
            "Epoch 2/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.5201 - accuracy: 0.0628 - val_loss: 1.5394 - val_accuracy: 0.1115\n",
            "Epoch 3/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.4852 - accuracy: 0.1268 - val_loss: 1.4893 - val_accuracy: 0.1277\n",
            "Epoch 4/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.4500 - accuracy: 0.1403 - val_loss: 1.4284 - val_accuracy: 0.1380\n",
            "Epoch 5/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.4113 - accuracy: 0.1404 - val_loss: 1.4023 - val_accuracy: 0.1422\n",
            "Epoch 6/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.3917 - accuracy: 0.1400 - val_loss: 1.4059 - val_accuracy: 0.1441\n",
            "Epoch 7/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.3786 - accuracy: 0.1554 - val_loss: 1.3812 - val_accuracy: 0.1492\n",
            "Epoch 8/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.3657 - accuracy: 0.1557 - val_loss: 1.3739 - val_accuracy: 0.1419\n",
            "Epoch 9/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.3607 - accuracy: 0.1547 - val_loss: 1.3569 - val_accuracy: 0.1573\n",
            "Epoch 10/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.3257 - accuracy: 0.2036 - val_loss: 1.3208 - val_accuracy: 0.2035\n",
            "Epoch 11/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.3045 - accuracy: 0.2124 - val_loss: 1.3153 - val_accuracy: 0.2177\n",
            "Epoch 12/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.2967 - accuracy: 0.2182 - val_loss: 1.3069 - val_accuracy: 0.2084\n",
            "Epoch 13/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.2901 - accuracy: 0.2076 - val_loss: 1.2714 - val_accuracy: 0.1935\n",
            "Epoch 14/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.2520 - accuracy: 0.1977 - val_loss: 1.2560 - val_accuracy: 0.1863\n",
            "Epoch 15/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.2447 - accuracy: 0.2067 - val_loss: 1.2586 - val_accuracy: 0.1847\n",
            "Epoch 16/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.2361 - accuracy: 0.2096 - val_loss: 1.2650 - val_accuracy: 0.1945\n",
            "Epoch 17/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.2270 - accuracy: 0.2099 - val_loss: 1.2459 - val_accuracy: 0.1968\n",
            "Epoch 18/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.2220 - accuracy: 0.2113 - val_loss: 1.2430 - val_accuracy: 0.2029\n",
            "Epoch 19/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.2242 - accuracy: 0.2135 - val_loss: 1.2414 - val_accuracy: 0.1809\n",
            "Epoch 20/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.2206 - accuracy: 0.2126 - val_loss: 1.2340 - val_accuracy: 0.2187\n",
            "Epoch 21/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.2086 - accuracy: 0.2128 - val_loss: 1.2070 - val_accuracy: 0.2135\n",
            "Epoch 22/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.1699 - accuracy: 0.2218 - val_loss: 1.1663 - val_accuracy: 0.2271\n",
            "Epoch 23/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.1396 - accuracy: 0.2286 - val_loss: 1.1578 - val_accuracy: 0.2311\n",
            "Epoch 24/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.1170 - accuracy: 0.2527 - val_loss: 1.1261 - val_accuracy: 0.2461\n",
            "Epoch 25/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0853 - accuracy: 0.2724 - val_loss: 1.1176 - val_accuracy: 0.2796\n",
            "Epoch 26/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0756 - accuracy: 0.2827 - val_loss: 1.0967 - val_accuracy: 0.2671\n",
            "Epoch 27/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0730 - accuracy: 0.2857 - val_loss: 1.1272 - val_accuracy: 0.2584\n",
            "Epoch 28/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0613 - accuracy: 0.2878 - val_loss: 1.1235 - val_accuracy: 0.2570\n",
            "Epoch 29/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0533 - accuracy: 0.2953 - val_loss: 1.1079 - val_accuracy: 0.2920\n",
            "Epoch 30/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.0399 - accuracy: 0.3064 - val_loss: 1.0886 - val_accuracy: 0.3120\n",
            "Epoch 31/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0325 - accuracy: 0.3118 - val_loss: 1.0979 - val_accuracy: 0.3019\n",
            "Epoch 32/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.0242 - accuracy: 0.3131 - val_loss: 1.0737 - val_accuracy: 0.3050\n",
            "Epoch 33/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.0194 - accuracy: 0.3204 - val_loss: 1.0680 - val_accuracy: 0.3122\n",
            "Epoch 34/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0173 - accuracy: 0.3211 - val_loss: 1.0709 - val_accuracy: 0.3376\n",
            "Epoch 35/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0140 - accuracy: 0.3197 - val_loss: 1.0628 - val_accuracy: 0.3152\n",
            "Epoch 36/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0121 - accuracy: 0.3249 - val_loss: 1.0834 - val_accuracy: 0.2822\n",
            "Epoch 37/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0084 - accuracy: 0.3217 - val_loss: 1.0572 - val_accuracy: 0.3030\n",
            "Epoch 38/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.0031 - accuracy: 0.3236 - val_loss: 1.0567 - val_accuracy: 0.3396\n",
            "Epoch 39/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9911 - accuracy: 0.3381 - val_loss: 1.0358 - val_accuracy: 0.3152\n",
            "Epoch 40/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9745 - accuracy: 0.3349 - val_loss: 1.0294 - val_accuracy: 0.3306\n",
            "Epoch 41/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9739 - accuracy: 0.3448 - val_loss: 1.0292 - val_accuracy: 0.3345\n",
            "Epoch 42/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9649 - accuracy: 0.3473 - val_loss: 1.0229 - val_accuracy: 0.3502\n",
            "Epoch 43/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9619 - accuracy: 0.3538 - val_loss: 1.0268 - val_accuracy: 0.3283\n",
            "Epoch 44/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9570 - accuracy: 0.3527 - val_loss: 1.0235 - val_accuracy: 0.3509\n",
            "Epoch 45/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9602 - accuracy: 0.3639 - val_loss: 1.0340 - val_accuracy: 0.3558\n",
            "Epoch 46/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9516 - accuracy: 0.3694 - val_loss: 1.0228 - val_accuracy: 0.3402\n",
            "Epoch 47/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9475 - accuracy: 0.3761 - val_loss: 1.0166 - val_accuracy: 0.3439\n",
            "Epoch 48/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9454 - accuracy: 0.3706 - val_loss: 1.0194 - val_accuracy: 0.3491\n",
            "Epoch 49/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9455 - accuracy: 0.3793 - val_loss: 1.0122 - val_accuracy: 0.3513\n",
            "Epoch 50/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9436 - accuracy: 0.3825 - val_loss: 1.0173 - val_accuracy: 0.3619\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WedZYSKAsN_h"
      },
      "source": [
        "o1=student1.get_layer(\"reqs1\").output\n",
        "\n",
        "output=Activation('relu')(o1)\n",
        "output2=Dropout(0.5)(output)\n",
        "output3=Dense(10,activation=\"softmax\", name=\"d1\")(output2)\n",
        "mm1=Model(student1.get_layer('s1').input, output3)\n",
        "my_weights=teacher.get_layer('dense_2').get_weights()\n",
        "\n",
        "# multi_model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSH6KXXIvNc9"
      },
      "source": [
        "mm1.get_layer('d1').set_weights(my_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSShbP9WvOVu"
      },
      "source": [
        "i=0\n",
        "for l in mm1.layers[:18]:\n",
        "  l.trainable=False\n",
        "  #print (l.name)\n",
        "  #print (i)\n",
        "  #i=i+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOtU-uPEvOSd"
      },
      "source": [
        "mm1.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdyalPuDvOPa",
        "outputId": "ac4f4a95-f492-4fb6-c7fa-95309be6acfd"
      },
      "source": [
        "batch_size = 256\n",
        "mm_history=mm1.fit(X_train, Y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=20,\n",
        "          verbose=1,\n",
        "          validation_data=(X_val, Y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "157/157 [==============================] - 3s 15ms/step - loss: 0.2709 - accuracy: 0.9223 - val_loss: 0.7129 - val_accuracy: 0.8175\n",
            "Epoch 2/20\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.2202 - accuracy: 0.9305 - val_loss: 0.6951 - val_accuracy: 0.8181\n",
            "Epoch 3/20\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.2107 - accuracy: 0.9330 - val_loss: 0.7046 - val_accuracy: 0.8197\n",
            "Epoch 4/20\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.2076 - accuracy: 0.9341 - val_loss: 0.6963 - val_accuracy: 0.8195\n",
            "Epoch 5/20\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.2030 - accuracy: 0.9348 - val_loss: 0.7047 - val_accuracy: 0.8186\n",
            "Epoch 6/20\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.1970 - accuracy: 0.9368 - val_loss: 0.6904 - val_accuracy: 0.8184\n",
            "Epoch 7/20\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.1886 - accuracy: 0.9406 - val_loss: 0.6991 - val_accuracy: 0.8192\n",
            "Epoch 8/20\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.1920 - accuracy: 0.9408 - val_loss: 0.7037 - val_accuracy: 0.8182\n",
            "Epoch 9/20\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.1897 - accuracy: 0.9389 - val_loss: 0.6967 - val_accuracy: 0.8203\n",
            "Epoch 10/20\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.1871 - accuracy: 0.9401 - val_loss: 0.7083 - val_accuracy: 0.8225\n",
            "Epoch 11/20\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.1850 - accuracy: 0.9393 - val_loss: 0.7066 - val_accuracy: 0.8180\n",
            "Epoch 12/20\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.1815 - accuracy: 0.9400 - val_loss: 0.7128 - val_accuracy: 0.8173\n",
            "Epoch 13/20\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.1916 - accuracy: 0.9354 - val_loss: 0.7401 - val_accuracy: 0.8193\n",
            "Epoch 14/20\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.1812 - accuracy: 0.9405 - val_loss: 0.7136 - val_accuracy: 0.8187\n",
            "Epoch 15/20\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.1765 - accuracy: 0.9420 - val_loss: 0.7086 - val_accuracy: 0.8213\n",
            "Epoch 16/20\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.1774 - accuracy: 0.9420 - val_loss: 0.7234 - val_accuracy: 0.8202\n",
            "Epoch 17/20\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.1738 - accuracy: 0.9417 - val_loss: 0.7175 - val_accuracy: 0.8204\n",
            "Epoch 18/20\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.1718 - accuracy: 0.9457 - val_loss: 0.7063 - val_accuracy: 0.8232\n",
            "Epoch 19/20\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.1722 - accuracy: 0.9418 - val_loss: 0.7248 - val_accuracy: 0.8226\n",
            "Epoch 20/20\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.1724 - accuracy: 0.9433 - val_loss: 0.7121 - val_accuracy: 0.8237\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntK1Ld0uw6in",
        "outputId": "7051641e-70e8-46a5-fa44-b3adf59f54d8"
      },
      "source": [
        "l,a = mm1.evaluate(X_test, y_test)\n",
        "l, a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7170 - accuracy: 0.8178\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7169958353042603, 0.817799985408783)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "230nT_NOw_d7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-UCfFcQxkEA"
      },
      "source": [
        "## 2 student"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ttHNvoaxjxW"
      },
      "source": [
        "s2 = define_model('s2')\n",
        "s1 = define_model('s1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgLufcwoxji6",
        "outputId": "0aaf7772-dc15-479e-b72e-81e9bead6917"
      },
      "source": [
        "history1=s1.fit(X_train,s1Train,\n",
        "          batch_size=256,\n",
        "          epochs=50,\n",
        "          verbose=1,\n",
        "          validation_data=(X_val,s1Val))\n",
        "\n",
        "history2=s2.fit(X_train,s2Train,\n",
        "          batch_size=256,\n",
        "          epochs=50,\n",
        "          verbose=1,\n",
        "          validation_data=(X_val,s2Val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "157/157 [==============================] - 5s 29ms/step - loss: 1.3712 - accuracy: 0.1065 - val_loss: 1.3905 - val_accuracy: 0.1021\n",
            "Epoch 2/50\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 1.3540 - accuracy: 0.1111 - val_loss: 1.3487 - val_accuracy: 0.1162\n",
            "Epoch 3/50\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 1.3390 - accuracy: 0.1295 - val_loss: 1.3456 - val_accuracy: 0.1153\n",
            "Epoch 4/50\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 1.3258 - accuracy: 0.1427 - val_loss: 1.3357 - val_accuracy: 0.1454\n",
            "Epoch 5/50\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 1.3010 - accuracy: 0.1544 - val_loss: 1.2977 - val_accuracy: 0.1653\n",
            "Epoch 6/50\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 1.2807 - accuracy: 0.1609 - val_loss: 1.2799 - val_accuracy: 0.1638\n",
            "Epoch 7/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 1.2693 - accuracy: 0.1636 - val_loss: 1.2750 - val_accuracy: 0.1512\n",
            "Epoch 8/50\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 1.2609 - accuracy: 0.1680 - val_loss: 1.2700 - val_accuracy: 0.1901\n",
            "Epoch 9/50\n",
            "157/157 [==============================] - 4s 29ms/step - loss: 1.2548 - accuracy: 0.1807 - val_loss: 1.2622 - val_accuracy: 0.1769\n",
            "Epoch 10/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.2380 - accuracy: 0.1909 - val_loss: 1.2220 - val_accuracy: 0.1782\n",
            "Epoch 11/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.1707 - accuracy: 0.2062 - val_loss: 1.2042 - val_accuracy: 0.1742\n",
            "Epoch 12/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.1415 - accuracy: 0.2256 - val_loss: 1.1501 - val_accuracy: 0.2307\n",
            "Epoch 13/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.1178 - accuracy: 0.2286 - val_loss: 1.1468 - val_accuracy: 0.2241\n",
            "Epoch 14/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.1036 - accuracy: 0.2255 - val_loss: 1.1239 - val_accuracy: 0.2231\n",
            "Epoch 15/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0933 - accuracy: 0.2286 - val_loss: 1.1302 - val_accuracy: 0.2201\n",
            "Epoch 16/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0854 - accuracy: 0.2360 - val_loss: 1.1097 - val_accuracy: 0.2318\n",
            "Epoch 17/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0780 - accuracy: 0.2400 - val_loss: 1.1043 - val_accuracy: 0.2520\n",
            "Epoch 18/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0728 - accuracy: 0.2508 - val_loss: 1.1074 - val_accuracy: 0.2518\n",
            "Epoch 19/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0684 - accuracy: 0.2598 - val_loss: 1.1065 - val_accuracy: 0.2450\n",
            "Epoch 20/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0630 - accuracy: 0.2672 - val_loss: 1.1317 - val_accuracy: 0.2708\n",
            "Epoch 21/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0581 - accuracy: 0.2746 - val_loss: 1.0865 - val_accuracy: 0.2743\n",
            "Epoch 22/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0333 - accuracy: 0.2810 - val_loss: 1.0744 - val_accuracy: 0.2860\n",
            "Epoch 23/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0242 - accuracy: 0.2848 - val_loss: 1.0718 - val_accuracy: 0.2770\n",
            "Epoch 24/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0151 - accuracy: 0.2852 - val_loss: 1.0699 - val_accuracy: 0.2678\n",
            "Epoch 25/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0105 - accuracy: 0.2891 - val_loss: 1.0623 - val_accuracy: 0.2746\n",
            "Epoch 26/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9975 - accuracy: 0.3113 - val_loss: 1.0465 - val_accuracy: 0.3105\n",
            "Epoch 27/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9852 - accuracy: 0.3226 - val_loss: 1.0332 - val_accuracy: 0.3115\n",
            "Epoch 28/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9773 - accuracy: 0.3753 - val_loss: 1.0311 - val_accuracy: 0.3610\n",
            "Epoch 29/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9733 - accuracy: 0.3801 - val_loss: 1.0297 - val_accuracy: 0.3645\n",
            "Epoch 30/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9675 - accuracy: 0.3857 - val_loss: 1.0348 - val_accuracy: 0.3488\n",
            "Epoch 31/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9652 - accuracy: 0.3864 - val_loss: 1.0258 - val_accuracy: 0.3658\n",
            "Epoch 32/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9637 - accuracy: 0.3866 - val_loss: 1.0246 - val_accuracy: 0.3555\n",
            "Epoch 33/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9602 - accuracy: 0.3869 - val_loss: 1.0214 - val_accuracy: 0.3787\n",
            "Epoch 34/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9569 - accuracy: 0.3907 - val_loss: 1.0171 - val_accuracy: 0.3834\n",
            "Epoch 35/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9546 - accuracy: 0.3933 - val_loss: 1.0226 - val_accuracy: 0.3728\n",
            "Epoch 36/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9527 - accuracy: 0.3948 - val_loss: 1.0238 - val_accuracy: 0.3635\n",
            "Epoch 37/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9508 - accuracy: 0.3943 - val_loss: 1.0252 - val_accuracy: 0.3581\n",
            "Epoch 38/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9483 - accuracy: 0.3981 - val_loss: 1.0353 - val_accuracy: 0.3673\n",
            "Epoch 39/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9456 - accuracy: 0.3988 - val_loss: 1.0226 - val_accuracy: 0.3797\n",
            "Epoch 40/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9445 - accuracy: 0.3992 - val_loss: 1.0191 - val_accuracy: 0.3738\n",
            "Epoch 41/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9419 - accuracy: 0.4022 - val_loss: 1.0228 - val_accuracy: 0.3642\n",
            "Epoch 42/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9416 - accuracy: 0.4034 - val_loss: 1.0227 - val_accuracy: 0.3709\n",
            "Epoch 43/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9401 - accuracy: 0.4068 - val_loss: 1.0171 - val_accuracy: 0.3836\n",
            "Epoch 44/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9385 - accuracy: 0.4065 - val_loss: 1.0347 - val_accuracy: 0.3592\n",
            "Epoch 45/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9376 - accuracy: 0.4071 - val_loss: 1.0197 - val_accuracy: 0.3914\n",
            "Epoch 46/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9370 - accuracy: 0.4082 - val_loss: 1.0194 - val_accuracy: 0.3762\n",
            "Epoch 47/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9355 - accuracy: 0.4072 - val_loss: 1.0121 - val_accuracy: 0.3775\n",
            "Epoch 48/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9340 - accuracy: 0.4077 - val_loss: 1.0145 - val_accuracy: 0.3810\n",
            "Epoch 49/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9313 - accuracy: 0.4123 - val_loss: 1.0185 - val_accuracy: 0.3706\n",
            "Epoch 50/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9331 - accuracy: 0.4079 - val_loss: 1.0143 - val_accuracy: 0.3833\n",
            "Epoch 1/50\n",
            "157/157 [==============================] - 5s 28ms/step - loss: 1.5766 - accuracy: 0.0817 - val_loss: 1.5032 - val_accuracy: 0.0337\n",
            "Epoch 2/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.4494 - accuracy: 0.0908 - val_loss: 1.4633 - val_accuracy: 0.0841\n",
            "Epoch 3/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.4172 - accuracy: 0.1298 - val_loss: 1.4388 - val_accuracy: 0.1283\n",
            "Epoch 4/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.4111 - accuracy: 0.1020 - val_loss: 1.4067 - val_accuracy: 0.1130\n",
            "Epoch 5/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.3957 - accuracy: 0.0911 - val_loss: 1.3619 - val_accuracy: 0.0870\n",
            "Epoch 6/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.3475 - accuracy: 0.0678 - val_loss: 1.3409 - val_accuracy: 0.0515\n",
            "Epoch 7/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.3301 - accuracy: 0.0635 - val_loss: 1.3435 - val_accuracy: 0.0703\n",
            "Epoch 8/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.3258 - accuracy: 0.0648 - val_loss: 1.3265 - val_accuracy: 0.0857\n",
            "Epoch 9/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.3154 - accuracy: 0.0783 - val_loss: 1.3077 - val_accuracy: 0.0643\n",
            "Epoch 10/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.2966 - accuracy: 0.0771 - val_loss: 1.2902 - val_accuracy: 0.0729\n",
            "Epoch 11/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.2810 - accuracy: 0.0755 - val_loss: 1.2505 - val_accuracy: 0.0680\n",
            "Epoch 12/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.2207 - accuracy: 0.1241 - val_loss: 1.2016 - val_accuracy: 0.2040\n",
            "Epoch 13/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.1742 - accuracy: 0.2060 - val_loss: 1.1577 - val_accuracy: 0.2688\n",
            "Epoch 14/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.1377 - accuracy: 0.2674 - val_loss: 1.1275 - val_accuracy: 0.3028\n",
            "Epoch 15/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.1208 - accuracy: 0.2918 - val_loss: 1.1226 - val_accuracy: 0.2796\n",
            "Epoch 16/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0941 - accuracy: 0.2938 - val_loss: 1.0527 - val_accuracy: 0.3133\n",
            "Epoch 17/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0260 - accuracy: 0.3119 - val_loss: 1.0524 - val_accuracy: 0.2792\n",
            "Epoch 18/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9912 - accuracy: 0.3273 - val_loss: 1.0358 - val_accuracy: 0.2965\n",
            "Epoch 19/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 0.9792 - accuracy: 0.3289 - val_loss: 1.0167 - val_accuracy: 0.2931\n",
            "Epoch 20/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9664 - accuracy: 0.3326 - val_loss: 0.9845 - val_accuracy: 0.3178\n",
            "Epoch 21/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9595 - accuracy: 0.3263 - val_loss: 0.9820 - val_accuracy: 0.3045\n",
            "Epoch 22/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9464 - accuracy: 0.3299 - val_loss: 0.9662 - val_accuracy: 0.3151\n",
            "Epoch 23/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 0.9423 - accuracy: 0.3325 - val_loss: 0.9795 - val_accuracy: 0.2995\n",
            "Epoch 24/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9333 - accuracy: 0.3297 - val_loss: 0.9651 - val_accuracy: 0.3344\n",
            "Epoch 25/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 0.9232 - accuracy: 0.3271 - val_loss: 0.9664 - val_accuracy: 0.3042\n",
            "Epoch 26/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9207 - accuracy: 0.3286 - val_loss: 0.9623 - val_accuracy: 0.3181\n",
            "Epoch 27/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9115 - accuracy: 0.3217 - val_loss: 0.9504 - val_accuracy: 0.3167\n",
            "Epoch 28/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 0.9113 - accuracy: 0.3297 - val_loss: 0.9616 - val_accuracy: 0.3238\n",
            "Epoch 29/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9108 - accuracy: 0.3238 - val_loss: 0.9544 - val_accuracy: 0.3266\n",
            "Epoch 30/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9040 - accuracy: 0.3318 - val_loss: 0.9507 - val_accuracy: 0.3184\n",
            "Epoch 31/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.8980 - accuracy: 0.3356 - val_loss: 0.9483 - val_accuracy: 0.3364\n",
            "Epoch 32/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.8976 - accuracy: 0.3365 - val_loss: 0.9535 - val_accuracy: 0.2966\n",
            "Epoch 33/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.8905 - accuracy: 0.3550 - val_loss: 0.9449 - val_accuracy: 0.3529\n",
            "Epoch 34/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 0.8892 - accuracy: 0.3708 - val_loss: 0.9445 - val_accuracy: 0.3583\n",
            "Epoch 35/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.8862 - accuracy: 0.3743 - val_loss: 0.9492 - val_accuracy: 0.3439\n",
            "Epoch 36/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.8893 - accuracy: 0.3699 - val_loss: 0.9400 - val_accuracy: 0.3465\n",
            "Epoch 37/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 0.8856 - accuracy: 0.3749 - val_loss: 0.9364 - val_accuracy: 0.3644\n",
            "Epoch 38/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.8833 - accuracy: 0.3713 - val_loss: 0.9507 - val_accuracy: 0.3557\n",
            "Epoch 39/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.8826 - accuracy: 0.3729 - val_loss: 0.9394 - val_accuracy: 0.3407\n",
            "Epoch 40/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 0.8862 - accuracy: 0.3716 - val_loss: 0.9481 - val_accuracy: 0.3323\n",
            "Epoch 41/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.8781 - accuracy: 0.3700 - val_loss: 0.9432 - val_accuracy: 0.3419\n",
            "Epoch 42/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.8737 - accuracy: 0.3809 - val_loss: 0.9246 - val_accuracy: 0.4002\n",
            "Epoch 43/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.8589 - accuracy: 0.4113 - val_loss: 0.9274 - val_accuracy: 0.4183\n",
            "Epoch 44/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.8547 - accuracy: 0.4166 - val_loss: 0.9217 - val_accuracy: 0.4103\n",
            "Epoch 45/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.8512 - accuracy: 0.4220 - val_loss: 0.9179 - val_accuracy: 0.4005\n",
            "Epoch 46/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.8466 - accuracy: 0.4338 - val_loss: 0.9334 - val_accuracy: 0.3884\n",
            "Epoch 47/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.8466 - accuracy: 0.4272 - val_loss: 0.9216 - val_accuracy: 0.3757\n",
            "Epoch 48/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 0.8443 - accuracy: 0.4363 - val_loss: 0.9163 - val_accuracy: 0.4071\n",
            "Epoch 49/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.8434 - accuracy: 0.4342 - val_loss: 0.9196 - val_accuracy: 0.4110\n",
            "Epoch 50/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.8426 - accuracy: 0.4310 - val_loss: 0.9180 - val_accuracy: 0.4117\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdOh_RHix6ZO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m4jX8v9y5Rw"
      },
      "source": [
        "o1=s1.get_layer(\"reqs1\").output\n",
        "o2=s2.get_layer(\"reqs2\").output\n",
        "output=tensorflow.keras.layers.concatenate([o1,o2])\n",
        "\n",
        "output=Activation('relu')(output)\n",
        "output2=Dropout(0.5)(output)\n",
        "output3=Dense(10,activation=\"softmax\", name=\"d1\")(output2)\n",
        "mm2=Model([s1.get_layer('s1').input, s2.get_layer('s2').input], output3)\n",
        "my_weights=teacher.get_layer('dense_2').get_weights()\n",
        "\n",
        "# multi_model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRlebK_5y5Ry"
      },
      "source": [
        "mm2.get_layer('d1').set_weights(my_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqFqqWRRy5Rz"
      },
      "source": [
        "i=0\n",
        "for l in mm2.layers[:18]:\n",
        "  l.trainable=False\n",
        "  #print (l.name)\n",
        "  #print (i)\n",
        "  #i=i+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ouMv4rQy5R0"
      },
      "source": [
        "mm2.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpcB5C_UyvIA",
        "outputId": "db8ed2e9-707e-4b36-b195-29b63970da92"
      },
      "source": [
        "epochs = 10\n",
        "batch_size = 256\n",
        "mm2_history=mm2.fit([X_train,X_train], Y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=20,\n",
        "          verbose=1,\n",
        "          validation_data=([X_val,X_val], Y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "157/157 [==============================] - 5s 34ms/step - loss: 0.0925 - accuracy: 0.9700 - val_loss: 0.7880 - val_accuracy: 0.8315\n",
            "Epoch 2/20\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.0904 - accuracy: 0.9699 - val_loss: 0.7829 - val_accuracy: 0.8344\n",
            "Epoch 3/20\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.0891 - accuracy: 0.9713 - val_loss: 0.7887 - val_accuracy: 0.8334\n",
            "Epoch 4/20\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.0878 - accuracy: 0.9714 - val_loss: 0.8102 - val_accuracy: 0.8322\n",
            "Epoch 5/20\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.0862 - accuracy: 0.9708 - val_loss: 0.7784 - val_accuracy: 0.8355\n",
            "Epoch 6/20\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.0883 - accuracy: 0.9706 - val_loss: 0.7793 - val_accuracy: 0.8354\n",
            "Epoch 7/20\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.0864 - accuracy: 0.9709 - val_loss: 0.8122 - val_accuracy: 0.8311\n",
            "Epoch 8/20\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.0858 - accuracy: 0.9717 - val_loss: 0.8051 - val_accuracy: 0.8388\n",
            "Epoch 9/20\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.0812 - accuracy: 0.9720 - val_loss: 0.8003 - val_accuracy: 0.8350\n",
            "Epoch 10/20\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.0864 - accuracy: 0.9710 - val_loss: 0.8740 - val_accuracy: 0.8228\n",
            "Epoch 11/20\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.0847 - accuracy: 0.9718 - val_loss: 0.7893 - val_accuracy: 0.8352\n",
            "Epoch 12/20\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.0836 - accuracy: 0.9719 - val_loss: 0.8220 - val_accuracy: 0.8372\n",
            "Epoch 13/20\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.0779 - accuracy: 0.9736 - val_loss: 0.7975 - val_accuracy: 0.8359\n",
            "Epoch 14/20\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.0830 - accuracy: 0.9732 - val_loss: 0.7924 - val_accuracy: 0.8353\n",
            "Epoch 15/20\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.0810 - accuracy: 0.9724 - val_loss: 0.8066 - val_accuracy: 0.8382\n",
            "Epoch 16/20\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.0772 - accuracy: 0.9748 - val_loss: 0.8320 - val_accuracy: 0.8375\n",
            "Epoch 17/20\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.0751 - accuracy: 0.9750 - val_loss: 0.8125 - val_accuracy: 0.8376\n",
            "Epoch 18/20\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.0814 - accuracy: 0.9733 - val_loss: 0.8109 - val_accuracy: 0.8354\n",
            "Epoch 19/20\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.0775 - accuracy: 0.9741 - val_loss: 0.8471 - val_accuracy: 0.8355\n",
            "Epoch 20/20\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.0765 - accuracy: 0.9757 - val_loss: 0.8581 - val_accuracy: 0.8336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgpeYmPDyvIC",
        "outputId": "6806c429-c0eb-4b45-e830-40a2865cc7da"
      },
      "source": [
        "l,a = mm2.evaluate([X_test,X_test], y_test)\n",
        "l, a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.9161 - accuracy: 0.8204\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.916100263595581, 0.8203999996185303)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lzM2BBWzU4F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REByDaop3fTe"
      },
      "source": [
        "## 4 students"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DVUbUQ53gu8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGg52IF13g73"
      },
      "source": [
        "s2 = define_model('s2')\n",
        "s1 = define_model('s1')\n",
        "s3 = define_model('s3')\n",
        "s4 = define_model('s4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ktbcZb23g74",
        "outputId": "3527fda3-6b5e-47ef-a376-5da3f543b1d0"
      },
      "source": [
        "history1=s1.fit(X_train,s1Train,\n",
        "          batch_size=256,\n",
        "          epochs=50,\n",
        "          verbose=1,\n",
        "          validation_data=(X_val,s1Val))\n",
        "\n",
        "history2=s2.fit(X_train,s2Train,\n",
        "          batch_size=256,\n",
        "          epochs=50,\n",
        "          verbose=1,\n",
        "          validation_data=(X_val,s2Val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "157/157 [==============================] - 6s 31ms/step - loss: 1.7302 - accuracy: 0.0964 - val_loss: 1.7280 - val_accuracy: 0.0930\n",
            "Epoch 2/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.6549 - accuracy: 0.1486 - val_loss: 1.6258 - val_accuracy: 0.1481\n",
            "Epoch 3/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.6119 - accuracy: 0.1461 - val_loss: 1.5905 - val_accuracy: 0.1476\n",
            "Epoch 4/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5838 - accuracy: 0.1467 - val_loss: 1.5690 - val_accuracy: 0.1465\n",
            "Epoch 5/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5637 - accuracy: 0.1486 - val_loss: 1.5552 - val_accuracy: 0.1462\n",
            "Epoch 6/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5584 - accuracy: 0.1469 - val_loss: 1.5466 - val_accuracy: 0.1462\n",
            "Epoch 7/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5422 - accuracy: 0.1457 - val_loss: 1.5414 - val_accuracy: 0.1462\n",
            "Epoch 8/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5352 - accuracy: 0.1477 - val_loss: 1.5382 - val_accuracy: 0.1462\n",
            "Epoch 9/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5349 - accuracy: 0.1495 - val_loss: 1.5364 - val_accuracy: 0.1462\n",
            "Epoch 10/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5392 - accuracy: 0.1469 - val_loss: 1.5353 - val_accuracy: 0.1462\n",
            "Epoch 11/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5283 - accuracy: 0.1470 - val_loss: 1.5347 - val_accuracy: 0.1462\n",
            "Epoch 12/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5384 - accuracy: 0.1464 - val_loss: 1.5344 - val_accuracy: 0.1462\n",
            "Epoch 13/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5312 - accuracy: 0.1469 - val_loss: 1.5342 - val_accuracy: 0.1462\n",
            "Epoch 14/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5362 - accuracy: 0.1472 - val_loss: 1.5341 - val_accuracy: 0.1462\n",
            "Epoch 15/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5318 - accuracy: 0.1483 - val_loss: 1.5341 - val_accuracy: 0.1462\n",
            "Epoch 16/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5300 - accuracy: 0.1468 - val_loss: 1.5341 - val_accuracy: 0.1462\n",
            "Epoch 17/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5340 - accuracy: 0.1449 - val_loss: 1.5341 - val_accuracy: 0.1462\n",
            "Epoch 18/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5224 - accuracy: 0.1419 - val_loss: 1.5340 - val_accuracy: 0.1462\n",
            "Epoch 19/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5291 - accuracy: 0.1436 - val_loss: 1.5341 - val_accuracy: 0.1462\n",
            "Epoch 20/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5353 - accuracy: 0.1456 - val_loss: 1.5340 - val_accuracy: 0.1462\n",
            "Epoch 21/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5335 - accuracy: 0.1430 - val_loss: 1.5340 - val_accuracy: 0.1462\n",
            "Epoch 22/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5346 - accuracy: 0.1458 - val_loss: 1.5340 - val_accuracy: 0.1462\n",
            "Epoch 23/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5326 - accuracy: 0.1473 - val_loss: 1.5340 - val_accuracy: 0.1462\n",
            "Epoch 24/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5320 - accuracy: 0.1450 - val_loss: 1.5341 - val_accuracy: 0.1462\n",
            "Epoch 25/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5386 - accuracy: 0.1485 - val_loss: 1.5341 - val_accuracy: 0.1462\n",
            "Epoch 26/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5308 - accuracy: 0.1452 - val_loss: 1.5341 - val_accuracy: 0.1462\n",
            "Epoch 27/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5305 - accuracy: 0.1447 - val_loss: 1.5340 - val_accuracy: 0.1462\n",
            "Epoch 28/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5342 - accuracy: 0.1486 - val_loss: 1.5341 - val_accuracy: 0.1462\n",
            "Epoch 29/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5282 - accuracy: 0.1471 - val_loss: 1.5341 - val_accuracy: 0.1462\n",
            "Epoch 30/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5383 - accuracy: 0.1457 - val_loss: 1.5340 - val_accuracy: 0.1462\n",
            "Epoch 31/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5325 - accuracy: 0.1463 - val_loss: 1.5341 - val_accuracy: 0.1462\n",
            "Epoch 32/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5285 - accuracy: 0.1482 - val_loss: 1.5341 - val_accuracy: 0.1462\n",
            "Epoch 33/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5345 - accuracy: 0.1491 - val_loss: 1.5341 - val_accuracy: 0.1462\n",
            "Epoch 34/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5303 - accuracy: 0.1439 - val_loss: 1.5341 - val_accuracy: 0.1462\n",
            "Epoch 35/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5347 - accuracy: 0.1453 - val_loss: 1.5341 - val_accuracy: 0.1462\n",
            "Epoch 36/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5363 - accuracy: 0.1453 - val_loss: 1.5340 - val_accuracy: 0.1462\n",
            "Epoch 37/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5293 - accuracy: 0.1449 - val_loss: 1.5340 - val_accuracy: 0.1462\n",
            "Epoch 38/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5333 - accuracy: 0.1474 - val_loss: 1.5341 - val_accuracy: 0.1462\n",
            "Epoch 39/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5348 - accuracy: 0.1469 - val_loss: 1.5341 - val_accuracy: 0.1462\n",
            "Epoch 40/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5287 - accuracy: 0.1463 - val_loss: 1.5340 - val_accuracy: 0.1462\n",
            "Epoch 41/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5310 - accuracy: 0.1465 - val_loss: 1.5341 - val_accuracy: 0.1462\n",
            "Epoch 42/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5369 - accuracy: 0.1487 - val_loss: 1.5341 - val_accuracy: 0.1462\n",
            "Epoch 43/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5365 - accuracy: 0.1497 - val_loss: 1.5341 - val_accuracy: 0.1462\n",
            "Epoch 44/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5313 - accuracy: 0.1458 - val_loss: 1.5341 - val_accuracy: 0.1462\n",
            "Epoch 45/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5321 - accuracy: 0.1438 - val_loss: 1.5340 - val_accuracy: 0.1462\n",
            "Epoch 46/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5296 - accuracy: 0.1445 - val_loss: 1.5340 - val_accuracy: 0.1462\n",
            "Epoch 47/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5373 - accuracy: 0.1462 - val_loss: 1.5341 - val_accuracy: 0.1462\n",
            "Epoch 48/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5260 - accuracy: 0.1455 - val_loss: 1.5340 - val_accuracy: 0.1462\n",
            "Epoch 49/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5356 - accuracy: 0.1475 - val_loss: 1.5341 - val_accuracy: 0.1462\n",
            "Epoch 50/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.5318 - accuracy: 0.1471 - val_loss: 1.5341 - val_accuracy: 0.1462\n",
            "Epoch 1/50\n",
            "157/157 [==============================] - 5s 28ms/step - loss: 1.5987 - accuracy: 0.0453 - val_loss: 1.8232 - val_accuracy: 0.0104\n",
            "Epoch 2/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.4871 - accuracy: 0.2197 - val_loss: 1.5197 - val_accuracy: 0.1331\n",
            "Epoch 3/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.4290 - accuracy: 0.2669 - val_loss: 1.4518 - val_accuracy: 0.2213\n",
            "Epoch 4/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.4119 - accuracy: 0.2653 - val_loss: 1.3879 - val_accuracy: 0.2420\n",
            "Epoch 5/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.3852 - accuracy: 0.2516 - val_loss: 1.3806 - val_accuracy: 0.2214\n",
            "Epoch 6/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.3719 - accuracy: 0.2094 - val_loss: 1.3629 - val_accuracy: 0.1342\n",
            "Epoch 7/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.3450 - accuracy: 0.1465 - val_loss: 1.3302 - val_accuracy: 0.1723\n",
            "Epoch 8/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.3143 - accuracy: 0.1469 - val_loss: 1.3172 - val_accuracy: 0.1254\n",
            "Epoch 9/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.3017 - accuracy: 0.1233 - val_loss: 1.3116 - val_accuracy: 0.1178\n",
            "Epoch 10/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.2807 - accuracy: 0.1481 - val_loss: 1.2621 - val_accuracy: 0.1665\n",
            "Epoch 11/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.2464 - accuracy: 0.1592 - val_loss: 1.2459 - val_accuracy: 0.1841\n",
            "Epoch 12/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.2346 - accuracy: 0.1653 - val_loss: 1.2314 - val_accuracy: 0.1682\n",
            "Epoch 13/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.2200 - accuracy: 0.1654 - val_loss: 1.2270 - val_accuracy: 0.1854\n",
            "Epoch 14/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.2110 - accuracy: 0.1726 - val_loss: 1.2164 - val_accuracy: 0.1776\n",
            "Epoch 15/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.2075 - accuracy: 0.1737 - val_loss: 1.2202 - val_accuracy: 0.1711\n",
            "Epoch 16/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.2023 - accuracy: 0.1908 - val_loss: 1.2101 - val_accuracy: 0.2043\n",
            "Epoch 17/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.1976 - accuracy: 0.1900 - val_loss: 1.2081 - val_accuracy: 0.2042\n",
            "Epoch 18/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.1927 - accuracy: 0.1933 - val_loss: 1.2095 - val_accuracy: 0.1939\n",
            "Epoch 19/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.1950 - accuracy: 0.1944 - val_loss: 1.2214 - val_accuracy: 0.2204\n",
            "Epoch 20/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.1854 - accuracy: 0.2101 - val_loss: 1.1717 - val_accuracy: 0.1834\n",
            "Epoch 21/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.1539 - accuracy: 0.2071 - val_loss: 1.1579 - val_accuracy: 0.1953\n",
            "Epoch 22/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.1454 - accuracy: 0.2050 - val_loss: 1.1565 - val_accuracy: 0.1989\n",
            "Epoch 23/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.1326 - accuracy: 0.1839 - val_loss: 1.1528 - val_accuracy: 0.1900\n",
            "Epoch 24/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.1296 - accuracy: 0.1926 - val_loss: 1.1606 - val_accuracy: 0.1550\n",
            "Epoch 25/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.1252 - accuracy: 0.1905 - val_loss: 1.1437 - val_accuracy: 0.1977\n",
            "Epoch 26/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.1228 - accuracy: 0.1960 - val_loss: 1.1502 - val_accuracy: 0.2016\n",
            "Epoch 27/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.1211 - accuracy: 0.2020 - val_loss: 1.1459 - val_accuracy: 0.2071\n",
            "Epoch 28/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.1184 - accuracy: 0.1951 - val_loss: 1.1372 - val_accuracy: 0.1849\n",
            "Epoch 29/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.1159 - accuracy: 0.1984 - val_loss: 1.1405 - val_accuracy: 0.2146\n",
            "Epoch 30/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.1141 - accuracy: 0.2048 - val_loss: 1.1391 - val_accuracy: 0.2076\n",
            "Epoch 31/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.1091 - accuracy: 0.2114 - val_loss: 1.1297 - val_accuracy: 0.2124\n",
            "Epoch 32/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0908 - accuracy: 0.2321 - val_loss: 1.1126 - val_accuracy: 0.2145\n",
            "Epoch 33/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0850 - accuracy: 0.2354 - val_loss: 1.1123 - val_accuracy: 0.2321\n",
            "Epoch 34/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0843 - accuracy: 0.2324 - val_loss: 1.1060 - val_accuracy: 0.2322\n",
            "Epoch 35/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0768 - accuracy: 0.2388 - val_loss: 1.1047 - val_accuracy: 0.2154\n",
            "Epoch 36/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0740 - accuracy: 0.2365 - val_loss: 1.1018 - val_accuracy: 0.2438\n",
            "Epoch 37/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0639 - accuracy: 0.2544 - val_loss: 1.0859 - val_accuracy: 0.2436\n",
            "Epoch 38/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0470 - accuracy: 0.2609 - val_loss: 1.0765 - val_accuracy: 0.2503\n",
            "Epoch 39/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0314 - accuracy: 0.2623 - val_loss: 1.0740 - val_accuracy: 0.2414\n",
            "Epoch 40/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0287 - accuracy: 0.2671 - val_loss: 1.0701 - val_accuracy: 0.2527\n",
            "Epoch 41/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0294 - accuracy: 0.2672 - val_loss: 1.0624 - val_accuracy: 0.3805\n",
            "Epoch 42/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.0049 - accuracy: 0.4267 - val_loss: 1.0354 - val_accuracy: 0.4330\n",
            "Epoch 43/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9874 - accuracy: 0.4551 - val_loss: 1.0270 - val_accuracy: 0.4252\n",
            "Epoch 44/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9795 - accuracy: 0.4599 - val_loss: 1.0271 - val_accuracy: 0.4491\n",
            "Epoch 45/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9806 - accuracy: 0.4568 - val_loss: 1.0347 - val_accuracy: 0.4317\n",
            "Epoch 46/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9723 - accuracy: 0.4617 - val_loss: 1.0368 - val_accuracy: 0.4231\n",
            "Epoch 47/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9730 - accuracy: 0.4605 - val_loss: 1.0207 - val_accuracy: 0.4408\n",
            "Epoch 48/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9715 - accuracy: 0.4681 - val_loss: 1.0217 - val_accuracy: 0.4591\n",
            "Epoch 49/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9675 - accuracy: 0.4715 - val_loss: 1.0146 - val_accuracy: 0.4523\n",
            "Epoch 50/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9674 - accuracy: 0.4708 - val_loss: 1.0176 - val_accuracy: 0.4436\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bj6OmQH33g76",
        "outputId": "fbe690a0-b24f-47d0-e521-22fa12d13592"
      },
      "source": [
        "history3 = s3.fit(X_train,s3Train,\n",
        "          batch_size=256,\n",
        "          epochs=50,\n",
        "          verbose=1,\n",
        "          validation_data=(X_val,s3Val))\n",
        "\n",
        "history4=s4.fit(X_train,s4Train,\n",
        "          batch_size=256,\n",
        "          epochs=50,\n",
        "          verbose=1,\n",
        "          validation_data=(X_val,s4Val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "157/157 [==============================] - 5s 28ms/step - loss: 1.4794 - accuracy: 0.0778 - val_loss: 1.5467 - val_accuracy: 0.0900\n",
            "Epoch 2/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.2718 - accuracy: 0.2064 - val_loss: 1.3213 - val_accuracy: 0.2275\n",
            "Epoch 3/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.1944 - accuracy: 0.2480 - val_loss: 1.2068 - val_accuracy: 0.3406\n",
            "Epoch 4/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.1463 - accuracy: 0.2772 - val_loss: 1.1500 - val_accuracy: 0.3217\n",
            "Epoch 5/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.1235 - accuracy: 0.3018 - val_loss: 1.1151 - val_accuracy: 0.3207\n",
            "Epoch 6/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.1039 - accuracy: 0.3128 - val_loss: 1.1109 - val_accuracy: 0.3246\n",
            "Epoch 7/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0895 - accuracy: 0.3177 - val_loss: 1.0868 - val_accuracy: 0.3221\n",
            "Epoch 8/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0752 - accuracy: 0.3255 - val_loss: 1.0590 - val_accuracy: 0.3205\n",
            "Epoch 9/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.0449 - accuracy: 0.3314 - val_loss: 1.0673 - val_accuracy: 0.2943\n",
            "Epoch 10/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0075 - accuracy: 0.3686 - val_loss: 1.0190 - val_accuracy: 0.3504\n",
            "Epoch 11/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 0.9893 - accuracy: 0.3944 - val_loss: 0.9907 - val_accuracy: 0.3844\n",
            "Epoch 12/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9645 - accuracy: 0.4085 - val_loss: 0.9703 - val_accuracy: 0.3985\n",
            "Epoch 13/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9490 - accuracy: 0.4109 - val_loss: 0.9715 - val_accuracy: 0.3654\n",
            "Epoch 14/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9350 - accuracy: 0.4097 - val_loss: 0.9501 - val_accuracy: 0.4211\n",
            "Epoch 15/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9259 - accuracy: 0.4174 - val_loss: 0.9428 - val_accuracy: 0.4219\n",
            "Epoch 16/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 0.9128 - accuracy: 0.4098 - val_loss: 0.9204 - val_accuracy: 0.4141\n",
            "Epoch 17/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.8874 - accuracy: 0.4257 - val_loss: 0.9022 - val_accuracy: 0.4078\n",
            "Epoch 18/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.8715 - accuracy: 0.4171 - val_loss: 0.8948 - val_accuracy: 0.4152\n",
            "Epoch 19/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.8592 - accuracy: 0.4266 - val_loss: 0.8980 - val_accuracy: 0.3866\n",
            "Epoch 20/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 0.8487 - accuracy: 0.4294 - val_loss: 0.8631 - val_accuracy: 0.4363\n",
            "Epoch 21/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.8239 - accuracy: 0.4486 - val_loss: 0.8485 - val_accuracy: 0.4621\n",
            "Epoch 22/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 0.8160 - accuracy: 0.4538 - val_loss: 0.8555 - val_accuracy: 0.4262\n",
            "Epoch 23/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.8061 - accuracy: 0.4537 - val_loss: 0.8424 - val_accuracy: 0.4527\n",
            "Epoch 24/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 0.7973 - accuracy: 0.4600 - val_loss: 0.8417 - val_accuracy: 0.4484\n",
            "Epoch 25/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.7986 - accuracy: 0.4619 - val_loss: 0.8405 - val_accuracy: 0.4837\n",
            "Epoch 26/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.7912 - accuracy: 0.4704 - val_loss: 0.8489 - val_accuracy: 0.4320\n",
            "Epoch 27/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 0.7873 - accuracy: 0.4711 - val_loss: 0.8277 - val_accuracy: 0.4684\n",
            "Epoch 28/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.7852 - accuracy: 0.4727 - val_loss: 0.8356 - val_accuracy: 0.4650\n",
            "Epoch 29/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.7805 - accuracy: 0.4699 - val_loss: 0.8269 - val_accuracy: 0.4638\n",
            "Epoch 30/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.7798 - accuracy: 0.4770 - val_loss: 0.8250 - val_accuracy: 0.4694\n",
            "Epoch 31/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.7797 - accuracy: 0.4723 - val_loss: 0.8229 - val_accuracy: 0.4594\n",
            "Epoch 32/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.7703 - accuracy: 0.4720 - val_loss: 0.8232 - val_accuracy: 0.4626\n",
            "Epoch 33/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.7634 - accuracy: 0.4700 - val_loss: 0.8144 - val_accuracy: 0.4443\n",
            "Epoch 34/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.7632 - accuracy: 0.4743 - val_loss: 0.8195 - val_accuracy: 0.4910\n",
            "Epoch 35/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.7633 - accuracy: 0.4810 - val_loss: 0.8301 - val_accuracy: 0.4414\n",
            "Epoch 36/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.7594 - accuracy: 0.4787 - val_loss: 0.8139 - val_accuracy: 0.4691\n",
            "Epoch 37/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.7551 - accuracy: 0.4755 - val_loss: 0.8100 - val_accuracy: 0.4575\n",
            "Epoch 38/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.7540 - accuracy: 0.4724 - val_loss: 0.8154 - val_accuracy: 0.4543\n",
            "Epoch 39/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.7513 - accuracy: 0.4706 - val_loss: 0.8336 - val_accuracy: 0.4735\n",
            "Epoch 40/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.7507 - accuracy: 0.4683 - val_loss: 0.8175 - val_accuracy: 0.4854\n",
            "Epoch 41/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.7470 - accuracy: 0.4641 - val_loss: 0.8108 - val_accuracy: 0.4618\n",
            "Epoch 42/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.7415 - accuracy: 0.4579 - val_loss: 0.8067 - val_accuracy: 0.4259\n",
            "Epoch 43/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.7328 - accuracy: 0.4552 - val_loss: 0.7876 - val_accuracy: 0.4366\n",
            "Epoch 44/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.7261 - accuracy: 0.4494 - val_loss: 0.7912 - val_accuracy: 0.4397\n",
            "Epoch 45/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.7242 - accuracy: 0.4498 - val_loss: 0.7902 - val_accuracy: 0.4042\n",
            "Epoch 46/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.7210 - accuracy: 0.4471 - val_loss: 0.7874 - val_accuracy: 0.4333\n",
            "Epoch 47/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.7184 - accuracy: 0.4417 - val_loss: 0.7882 - val_accuracy: 0.4228\n",
            "Epoch 48/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.7142 - accuracy: 0.4439 - val_loss: 0.7852 - val_accuracy: 0.4114\n",
            "Epoch 49/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.7128 - accuracy: 0.4384 - val_loss: 0.7805 - val_accuracy: 0.4134\n",
            "Epoch 50/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.7098 - accuracy: 0.4416 - val_loss: 0.7784 - val_accuracy: 0.4300\n",
            "Epoch 1/50\n",
            "157/157 [==============================] - 5s 28ms/step - loss: 1.7044 - accuracy: 0.1206 - val_loss: 1.5827 - val_accuracy: 0.0849\n",
            "Epoch 2/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.5041 - accuracy: 0.2086 - val_loss: 1.5200 - val_accuracy: 0.1157\n",
            "Epoch 3/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.4572 - accuracy: 0.1871 - val_loss: 1.4675 - val_accuracy: 0.1515\n",
            "Epoch 4/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.4241 - accuracy: 0.1540 - val_loss: 1.4235 - val_accuracy: 0.1569\n",
            "Epoch 5/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.4084 - accuracy: 0.1571 - val_loss: 1.4046 - val_accuracy: 0.1573\n",
            "Epoch 6/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.3986 - accuracy: 0.1536 - val_loss: 1.3947 - val_accuracy: 0.1462\n",
            "Epoch 7/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.3818 - accuracy: 0.1552 - val_loss: 1.3698 - val_accuracy: 0.1401\n",
            "Epoch 8/50\n",
            "157/157 [==============================] - 4s 26ms/step - loss: 1.3549 - accuracy: 0.1660 - val_loss: 1.3626 - val_accuracy: 0.1252\n",
            "Epoch 9/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.3322 - accuracy: 0.1746 - val_loss: 1.3166 - val_accuracy: 0.1370\n",
            "Epoch 10/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.2950 - accuracy: 0.1776 - val_loss: 1.3058 - val_accuracy: 0.0806\n",
            "Epoch 11/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.2473 - accuracy: 0.1647 - val_loss: 1.2352 - val_accuracy: 0.1480\n",
            "Epoch 12/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.2129 - accuracy: 0.1960 - val_loss: 1.1976 - val_accuracy: 0.1756\n",
            "Epoch 13/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.1804 - accuracy: 0.2291 - val_loss: 1.1713 - val_accuracy: 0.2358\n",
            "Epoch 14/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.1595 - accuracy: 0.2646 - val_loss: 1.1570 - val_accuracy: 0.2660\n",
            "Epoch 15/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.1404 - accuracy: 0.2785 - val_loss: 1.1512 - val_accuracy: 0.2594\n",
            "Epoch 16/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.1230 - accuracy: 0.2870 - val_loss: 1.1359 - val_accuracy: 0.2933\n",
            "Epoch 17/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.1170 - accuracy: 0.2968 - val_loss: 1.1280 - val_accuracy: 0.2893\n",
            "Epoch 18/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0965 - accuracy: 0.3129 - val_loss: 1.1078 - val_accuracy: 0.3069\n",
            "Epoch 19/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0839 - accuracy: 0.3144 - val_loss: 1.1025 - val_accuracy: 0.2907\n",
            "Epoch 20/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0700 - accuracy: 0.3214 - val_loss: 1.1110 - val_accuracy: 0.3203\n",
            "Epoch 21/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0656 - accuracy: 0.3275 - val_loss: 1.0965 - val_accuracy: 0.2938\n",
            "Epoch 22/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0568 - accuracy: 0.3187 - val_loss: 1.1011 - val_accuracy: 0.3147\n",
            "Epoch 23/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0531 - accuracy: 0.3307 - val_loss: 1.0861 - val_accuracy: 0.3111\n",
            "Epoch 24/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0472 - accuracy: 0.3351 - val_loss: 1.0902 - val_accuracy: 0.3362\n",
            "Epoch 25/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0465 - accuracy: 0.3444 - val_loss: 1.0900 - val_accuracy: 0.3452\n",
            "Epoch 26/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0424 - accuracy: 0.3492 - val_loss: 1.0824 - val_accuracy: 0.3362\n",
            "Epoch 27/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0352 - accuracy: 0.3463 - val_loss: 1.0782 - val_accuracy: 0.3475\n",
            "Epoch 28/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0338 - accuracy: 0.3460 - val_loss: 1.0739 - val_accuracy: 0.3196\n",
            "Epoch 29/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0242 - accuracy: 0.3550 - val_loss: 1.0780 - val_accuracy: 0.3317\n",
            "Epoch 30/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0188 - accuracy: 0.3505 - val_loss: 1.0737 - val_accuracy: 0.3310\n",
            "Epoch 31/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0191 - accuracy: 0.3535 - val_loss: 1.0696 - val_accuracy: 0.3324\n",
            "Epoch 32/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0186 - accuracy: 0.3594 - val_loss: 1.0761 - val_accuracy: 0.3220\n",
            "Epoch 33/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0163 - accuracy: 0.3591 - val_loss: 1.0790 - val_accuracy: 0.3256\n",
            "Epoch 34/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0153 - accuracy: 0.3563 - val_loss: 1.0734 - val_accuracy: 0.3227\n",
            "Epoch 35/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0122 - accuracy: 0.3581 - val_loss: 1.0707 - val_accuracy: 0.3425\n",
            "Epoch 36/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0140 - accuracy: 0.3577 - val_loss: 1.0817 - val_accuracy: 0.3305\n",
            "Epoch 37/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0131 - accuracy: 0.3609 - val_loss: 1.0697 - val_accuracy: 0.3459\n",
            "Epoch 38/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0091 - accuracy: 0.3638 - val_loss: 1.0695 - val_accuracy: 0.3440\n",
            "Epoch 39/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0078 - accuracy: 0.3652 - val_loss: 1.0736 - val_accuracy: 0.3344\n",
            "Epoch 40/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0092 - accuracy: 0.3702 - val_loss: 1.0695 - val_accuracy: 0.3375\n",
            "Epoch 41/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0040 - accuracy: 0.3633 - val_loss: 1.0723 - val_accuracy: 0.3339\n",
            "Epoch 42/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0035 - accuracy: 0.3668 - val_loss: 1.0704 - val_accuracy: 0.3302\n",
            "Epoch 43/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0004 - accuracy: 0.3677 - val_loss: 1.0671 - val_accuracy: 0.3425\n",
            "Epoch 44/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 1.0059 - accuracy: 0.3721 - val_loss: 1.0645 - val_accuracy: 0.3745\n",
            "Epoch 45/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9986 - accuracy: 0.4223 - val_loss: 1.0549 - val_accuracy: 0.4162\n",
            "Epoch 46/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9885 - accuracy: 0.4320 - val_loss: 1.0650 - val_accuracy: 0.3956\n",
            "Epoch 47/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9912 - accuracy: 0.4440 - val_loss: 1.0525 - val_accuracy: 0.4292\n",
            "Epoch 48/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9850 - accuracy: 0.4377 - val_loss: 1.0515 - val_accuracy: 0.4320\n",
            "Epoch 49/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9747 - accuracy: 0.4540 - val_loss: 1.0589 - val_accuracy: 0.3915\n",
            "Epoch 50/50\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.9764 - accuracy: 0.4463 - val_loss: 1.0562 - val_accuracy: 0.4230\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUW0Ff2o3g77"
      },
      "source": [
        "o1=s1.get_layer(\"reqs1\").output\n",
        "o2=s2.get_layer(\"reqs2\").output\n",
        "o3=s3.get_layer(\"reqs3\").output\n",
        "o4=s4.get_layer(\"reqs4\").output\n",
        "output=tensorflow.keras.layers.concatenate([o1,o2,o3,o4])\n",
        "\n",
        "output=Activation('relu')(output)\n",
        "output2=Dropout(0.5)(output)\n",
        "output3=Dense(10,activation=\"softmax\", name=\"d1\")(output2)\n",
        "mm2=Model([s1.get_layer('s1').input, \n",
        "           s2.get_layer('s2').input,\n",
        "           s3.get_layer('s3').input,\n",
        "           s4.get_layer('s4').input], output3)\n",
        "my_weights=teacher.get_layer('dense_2').get_weights()\n",
        "\n",
        "# multi_model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYIGgP4C3g78"
      },
      "source": [
        "mm2.get_layer('d1').set_weights(my_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzyW_5Oy4jdw"
      },
      "source": [
        "i=0\n",
        "for l in mm2.layers[:len(mm2.layers)-1]:\n",
        "    l.trainable=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sx5pzI7k3g7-"
      },
      "source": [
        "mm2.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXq5D5cC3g7_",
        "outputId": "5ece5752-9780-4103-9f60-e535ff499ef8"
      },
      "source": [
        "epochs = 10\n",
        "batch_size = 256\n",
        "mm2_history=mm2.fit([X_train,X_train,X_train,X_train], Y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=5,\n",
        "          verbose=1,\n",
        "          validation_data=([X_val,X_val,X_val,X_val], Y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "157/157 [==============================] - 9s 48ms/step - loss: 0.7834 - accuracy: 0.7983 - val_loss: 0.5761 - val_accuracy: 0.8477\n",
            "Epoch 2/5\n",
            "157/157 [==============================] - 6s 41ms/step - loss: 0.3492 - accuracy: 0.9070 - val_loss: 0.5813 - val_accuracy: 0.8484\n",
            "Epoch 3/5\n",
            "157/157 [==============================] - 6s 41ms/step - loss: 0.3248 - accuracy: 0.9135 - val_loss: 0.5656 - val_accuracy: 0.8507\n",
            "Epoch 4/5\n",
            "157/157 [==============================] - 6s 41ms/step - loss: 0.3056 - accuracy: 0.9195 - val_loss: 0.5548 - val_accuracy: 0.8503\n",
            "Epoch 5/5\n",
            "157/157 [==============================] - 6s 41ms/step - loss: 0.2868 - accuracy: 0.9235 - val_loss: 0.5435 - val_accuracy: 0.8510\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GKEMWisA-bQ",
        "outputId": "9b2f6107-b934-4a62-dd3f-0c6383ea172f"
      },
      "source": [
        "mm2_history=mm2.fit([X_train,X_train,X_train,X_train], Y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=5,\n",
        "          verbose=1,\n",
        "          validation_data=([X_val,X_val,X_val,X_val], Y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "157/157 [==============================] - 8s 49ms/step - loss: 0.2699 - accuracy: 0.9272 - val_loss: 0.5343 - val_accuracy: 0.8506\n",
            "Epoch 2/5\n",
            "157/157 [==============================] - 6s 41ms/step - loss: 0.2713 - accuracy: 0.9263 - val_loss: 0.5247 - val_accuracy: 0.8504\n",
            "Epoch 3/5\n",
            "157/157 [==============================] - 6s 41ms/step - loss: 0.2663 - accuracy: 0.9270 - val_loss: 0.5160 - val_accuracy: 0.8504\n",
            "Epoch 4/5\n",
            "157/157 [==============================] - 6s 41ms/step - loss: 0.2604 - accuracy: 0.9270 - val_loss: 0.5133 - val_accuracy: 0.8498\n",
            "Epoch 5/5\n",
            "157/157 [==============================] - 7s 42ms/step - loss: 0.2582 - accuracy: 0.9284 - val_loss: 0.5065 - val_accuracy: 0.8509\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fv7BdZJe3g8A",
        "outputId": "34f6aeb3-c3d6-4102-a0a0-123624eedb31"
      },
      "source": [
        "l,a = mm2.evaluate([X_test,X_test,X_test,X_test], y_test)\n",
        "l, a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 6ms/step - loss: 0.5463 - accuracy: 0.8420\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5462550520896912, 0.8420000076293945)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8T6wQOG4xU_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}